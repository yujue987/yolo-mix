# YOLOv1 & YOLOv2 & YOLOv4 å®ç°ä¿®æ”¹è®°å½•

## é¡¹ç›®æ¦‚è¿°

åŸºäº Ultralytics YOLO æ¡†æ¶å®ç° YOLOv1ã€YOLOv2 å’Œ YOLOv4 æ¨¡å‹ï¼ŒåŒ…å«å®Œæ•´çš„æ¨¡å—å®ç°ã€æŸå¤±å‡½æ•°å’Œè®­ç»ƒé…ç½®ã€‚

---

## ğŸ”¥ YOLOv4 å®ç°ä¿®æ”¹è®°å½•

### ğŸ“‹ YOLOv4 ä¿®æ”¹æ–‡ä»¶æ¸…å•

#### 1. æ ¸å¿ƒæ¨¡å—å®ç°

##### 1.1 `ultralytics/nn/modules/block.py` - æ·»åŠ  CSPBlock æ¨¡å—

**ä¿®æ”¹ä½ç½®**: ç¬¬ 2008-2077 è¡Œ
**ä¿®æ”¹å†…å®¹**: æ–°å¢ CSPBlock ç±»

```python
class CSPBlock(nn.Module):
    """
    CSP (Cross Stage Partial) Block for YOLOv4.

    This module implements the CSP architecture used in YOLOv4, which enhances
    gradient information flow and reduces computational cost by splitting the
    feature map into two parts and merging them after processing.

    Args:
        c1 (int): Input channels
        c2 (int, optional): Output channels. If None, equals c1
        n (int): Number of BottleneckCSP blocks
        shortcut (bool): Whether to use shortcut connection
        g (int): Groups for convolution
        e (float): Expansion ratio

    Examples:
        >>> csp_block = CSPBlock(128, 256, n=3)
        >>> x = torch.randn(1, 128, 32, 32)
        >>> output = csp_block(x)  # Output: (1, 256, 32, 32)
    """

    def __init__(self, c1, c2=None, n=1, shortcut=True, g=1, e=0.5):
        """Initialize CSP block with input/output channels and configuration."""
        super().__init__()
        if c2 is None:
            c2 = c1
        self.csp = BottleneckCSP(c1, c2, n, shortcut, g, e)

        # Add export attribute for compatibility
        self.export = False
        self.format = 'onnx'
        self.dynamic = False

    def forward(self, x):
        """Forward pass through CSP block."""
        return self.csp(x)
```

**ç”¨é€”**: å®ç° YOLOv4 çš„ CSP (Cross Stage Partial) æ¨¡å—ï¼ŒåŸºäºç°æœ‰çš„ BottleneckCSP å®ç°ï¼Œæä¾› YOLOv4 ä¸“ç”¨æ¥å£ï¼Œå¢å¼ºæ¢¯åº¦ä¿¡æ¯æµå¹¶å‡å°‘è®¡ç®—æˆæœ¬

##### 1.2 `ultralytics/nn/modules/head.py` - æ·»åŠ  YOLOv4Detect æ£€æµ‹å¤´

**ä¿®æ”¹ä½ç½®**: ç¬¬ 836-987 è¡Œ
**ä¿®æ”¹å†…å®¹**: æ–°å¢ YOLOv4Detect ç±»

```python
class YOLOv4Detect(nn.Module):
    """
    YOLOv4 detection head for object detection.

    This detection head implements YOLOv4's detection mechanism with multiple scales
    and anchor boxes. It supports 3 detection layers for different object sizes.

    Attributes:
        nc (int): Number of classes
        anchors (tuple): Anchor boxes configuration
        ch (tuple): Input channel numbers for each detection layer
        inplace (bool): Whether to use inplace operations
        na (int): Number of anchors per detection layer (typically 3)
        no (int): Number of outputs per anchor (nc + 5 for bbox + objectness)
        nl (int): Number of detection layers (typically 3)
        stride (torch.Tensor): Stride values for each detection layer

    Examples:
        >>> anchors = ((12,16,19,36,40,28), (36,75,76,55,72,146), (142,110,192,243,459,401))
        >>> ch = (128, 256, 512)
        >>> detect_head = YOLOv4Detect(nc=80, anchors=anchors, ch=ch)
        >>> outputs = detect_head([torch.randn(1, 128, 80, 80),
        ...                       torch.randn(1, 256, 40, 40),
        ...                       torch.randn(1, 512, 20, 20)])
    """

    def __init__(self, nc=80, ch=(), anchors=(), inplace=True):
        """Initialize YOLOv4 detection head with specified parameters."""
        super().__init__()
        self.nc = nc  # number of classes
        self.no = nc + 5  # number of outputs per anchor (4 bbox + 1 objectness + nc classes)
        self.nl = len(ch) if ch else 3  # number of detection layers
        self.na = 3  # number of anchors per layer (YOLOv4 uses 3)
        self.ch = ch
        self.inplace = inplace

        # Default YOLOv4 anchors if not provided
        if not anchors:
            anchors = ((12, 16, 19, 36, 40, 28),
                      (36, 75, 76, 55, 72, 146),
                      (142, 110, 192, 243, 459, 401))

        # Process anchors
        self.anchors = torch.tensor(anchors, dtype=torch.float32).view(self.nl, -1, 2)
        self.na = self.anchors.shape[1]  # number of anchors per layer

        # Detection layers
        self.m = nn.ModuleList(nn.Conv2d(x, self.no * self.na, 1) for x in ch)

        # Initialize stride and grid
        self.stride = torch.tensor([8., 16., 32.])  # YOLOv4 strides
        self.anchors /= self.stride.view(-1, 1, 1)  # normalize anchors

        # Initialize grids
        self.grid = [torch.zeros(1)] * self.nl

        # Framework compatibility attributes
        self.export = False
        self.format = 'onnx'
        self.dynamic = False
        self.shape = None

    def forward(self, x):
        """Forward pass through YOLOv4 detection head."""
        z = []  # inference output

        for i in range(self.nl):
            x[i] = self.m[i](x[i])  # conv
            bs, _, ny, nx = x[i].shape  # batch_size, channels, grid_y, grid_x

            # Reshape: (bs, na*no, ny, nx) -> (bs, na, no, ny, nx) -> (bs, na, ny, nx, no)
            x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()

            if not self.training:  # inference
                if self.grid[i].shape[2:4] != x[i].shape[2:4]:
                    self.grid[i] = self._make_grid(nx, ny).to(x[i].device)

                # Apply sigmoid to xy coordinates and objectness
                xy = (x[i][..., 0:2].sigmoid() + self.grid[i]) * self.stride[i]  # xy
                wh = (x[i][..., 2:4].exp() * self.anchors[i]) * self.stride[i]  # wh
                conf = x[i][..., 4:].sigmoid()  # confidence and classes

                # Concatenate and reshape for inference
                pred = torch.cat((xy, wh, conf), -1)
                z.append(pred.view(bs, -1, self.no))

        return x if self.training else (torch.cat(z, 1), x)

    def _make_grid(self, nx=20, ny=20):
        """Generate grid for anchor boxes."""
        yv, xv = torch.meshgrid(torch.arange(ny), torch.arange(nx), indexing='ij')
        return torch.stack((xv, yv), 2).view((1, 1, ny, nx, 2)).float()
```

**ç”¨é€”**: å®ç° YOLOv4 æ£€æµ‹å¤´ï¼Œæ”¯æŒ 3 ä¸ªæ£€æµ‹å°ºåº¦ï¼Œæ¯ä¸ªå°ºåº¦ä½¿ç”¨ 3 ä¸ª anchor boxesï¼Œæä¾›å¤šå°ºåº¦ç›®æ ‡æ£€æµ‹èƒ½åŠ›å’Œæ›´å‡†ç¡®çš„è¾¹ç•Œæ¡†é¢„æµ‹

#### 2. é…ç½®æ–‡ä»¶

##### 2.1 `ultralytics/cfg/models/v4-/yolov4.yaml` - YOLOv4 ç½‘ç»œç»“æ„é…ç½®

**æ–‡ä»¶å†…å®¹**: å®Œæ•´é‡æ„çš„ YOLOv4 é…ç½®æ–‡ä»¶

```yaml
# YOLOv4 ç½‘ç»œç»“æ„é…ç½®æ–‡ä»¶ - ç®€åŒ–ç‰ˆæœ¬
# å‚è€ƒ: YOLOv4: Optimal Speed and Accuracy of Object Detection

# å‚æ•°é…ç½®
nc: 80 # COCOæ•°æ®é›†80ä¸ªç±»åˆ«
depth_multiple: 1.0
width_multiple: 1.0
anchors:
  - [12, 16, 19, 36, 40, 28] # P3/8
  - [36, 75, 76, 55, 72, 146] # P4/16
  - [142, 110, 192, 243, 459, 401] # P5/32

# CSPDarknet53 éª¨å¹²ç½‘ç»œ - ç®€åŒ–ç‰ˆæœ¬
backbone:
  # [from, number, module, args]
  - [-1, 1, Conv, [32, 3, 2]] # 0-P1/2
  - [-1, 1, Conv, [64, 3, 2]] # 1-P2/4
  - [-1, 1, CSPBlock, [64]] # 2
  - [-1, 1, Conv, [128, 3, 2]] # 3-P3/8
  - [-1, 3, CSPBlock, [128]] # 4
  - [-1, 1, Conv, [256, 3, 2]] # 5-P4/16
  - [-1, 3, CSPBlock, [256]] # 6
  - [-1, 1, Conv, [512, 3, 2]] # 7-P5/32
  - [-1, 3, CSPBlock, [512]] # 8
  - [-1, 1, SPP, [512, [5, 9, 13]]] # 9 SPPæ¨¡å—

# é¢ˆéƒ¨ç½‘ç»œ (Neck): SPP + PANet - ç®€åŒ–ç‰ˆæœ¬
head:
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]] # 10
  - [[-1, 6], 1, Concat, [1]] # 11 cat backbone P4
  - [-1, 3, CSPBlock, [256]] # 12

  - [-1, 1, nn.Upsample, [None, 2, "nearest"]] # 13
  - [[-1, 4], 1, Concat, [1]] # 14 cat backbone P3
  - [-1, 3, CSPBlock, [128]] # 15 (P3/8-small)

  - [-1, 1, Conv, [256, 3, 2]] # 16
  - [[-1, 12], 1, Concat, [1]] # 17 cat head P4
  - [-1, 3, CSPBlock, [256]] # 18 (P4/16-medium)

  - [-1, 1, Conv, [512, 3, 2]] # 19
  - [[-1, 9], 1, Concat, [1]] # 20 cat head P5
  - [-1, 3, CSPBlock, [512]] # 21 (P5/32-large)

  - [[15, 18, 21], 1, YOLOv4Detect, [nc]] # 22 YOLOv4 Detection
```

**ç”¨é€”**: å®šä¹‰ YOLOv4 çš„ç½‘ç»œç»“æ„ï¼ŒåŒ…å« CSPDarknet53 éª¨å¹²ç½‘ç»œã€SPP + PANet é¢ˆéƒ¨ç½‘ç»œï¼Œä»¥åŠ YOLOv4Detect æ£€æµ‹å¤´ã€‚ä¿®æ­£äº†åŸå§‹é…ç½®ä¸­çš„å±‚ç´¢å¼•é—®é¢˜ï¼Œä½¿ç”¨æ­£ç¡®çš„å±‚å¼•ç”¨ [15, 18, 21]

#### 3. æ¨¡å—å¯¼å…¥å’Œæ³¨å†Œ

##### 3.1 `ultralytics/nn/modules/__init__.py` - æ·»åŠ æ¨¡å—å¯¼å…¥

**ä¿®æ”¹ä½ç½®**:

- ç¬¬ 58 è¡Œ: åœ¨ block æ¨¡å—å¯¼å…¥åˆ—è¡¨æœ«å°¾æ·»åŠ  `CSPBlock` å¯¼å…¥
- ç¬¬ 75 è¡Œ: åœ¨ head æ¨¡å—å¯¼å…¥åˆ—è¡¨æœ«å°¾æ·»åŠ  `YOLOv4Detect` å¯¼å…¥
- ç¬¬ 157 è¡Œ: åœ¨ `__all__` åˆ—è¡¨ä¸­æ·»åŠ  `"YOLOv4Detect"`
- ç¬¬ 180 è¡Œ: åœ¨ `__all__` åˆ—è¡¨æœ«å°¾æ·»åŠ  `"CSPBlock"`

**ä¿®æ”¹å†…å®¹**:

```python
# ç¬¬ 58 è¡Œæ·»åŠ 
CSPBlock  # YOLOv4

# ç¬¬ 75 è¡Œæ·»åŠ 
YOLOv4Detect

# ç¬¬ 157 è¡Œæ·»åŠ 
"YOLOv4Detect",

# ç¬¬ 180 è¡Œæ·»åŠ 
"CSPBlock",
```

**ç”¨é€”**: å°† CSPBlock å’Œ YOLOv4Detect æ¨¡å—æ³¨å†Œåˆ°æ¡†æ¶ä¸­ï¼Œä½¿å…¶å¯ä»¥åœ¨ YAML é…ç½®æ–‡ä»¶ä¸­ä½¿ç”¨

##### 3.2 `ultralytics/nn/tasks.py` - æ·»åŠ æ¨¡å—æ”¯æŒ

**ä¿®æ”¹ä½ç½®**:

- ç¬¬ 62 è¡Œ: æ·»åŠ  CSPBlock å¯¼å…¥
- ç¬¬ 63 è¡Œ: æ·»åŠ  YOLOv4Detect å¯¼å…¥
- ç¬¬ 1082 è¡Œ: åœ¨ parse_model å‡½æ•°ä¸­æ·»åŠ  CSPBlock ç‰¹æ®Šå¤„ç†
- ç¬¬ 1227 è¡Œ: åœ¨ guess_model_task å‡½æ•°ä¸­æ·»åŠ  YOLOv4Detect è¯†åˆ«

**ä¿®æ”¹å†…å®¹**:

```python
# ç¬¬ 62-63 è¡Œæ·»åŠ å¯¼å…¥
from .modules.block import CSPBlock
from .modules.head import YOLOv4Detect

# ç¬¬ 1082 è¡Œæ·»åŠ 
elif m is CSPBlock:
    c2 = args[0] if args[0] is not None else c1
    args = [c1, c2, *args[1:]]
    if args[1] != args[0]:  # c1 != c2
        args.insert(2, n)  # number of blocks
        n = 1

# ç¬¬ 1227 è¡Œæ·»åŠ 
"YOLOv4Detect": "detect",
```

**ç”¨é€”**: æ”¯æŒ YOLOv4 æ¨¡å—çš„è§£æå’Œä»»åŠ¡è¯†åˆ«ï¼Œä½¿æ¡†æ¶èƒ½å¤Ÿæ­£ç¡®å¤„ç† CSPBlock å’Œ YOLOv4Detect æ¨¡å—

#### 4. æµ‹è¯•å’ŒéªŒè¯

##### 4.1 `test_yolov4.py` - YOLOv4 æµ‹è¯•è„šæœ¬

**æ–‡ä»¶å†…å®¹**: å®Œæ•´çš„ YOLOv4 æ¨¡å‹æµ‹è¯•è„šæœ¬

```python
#!/usr/bin/env python3
"""
YOLOv4 æ¨¡å‹åˆ›å»ºå’Œæµ‹è¯•è„šæœ¬
"""

import torch
from ultralytics import YOLO

def test_yolov4_model():
    """æµ‹è¯•YOLOv4æ¨¡å‹åˆ›å»ºå’ŒåŸºæœ¬åŠŸèƒ½"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•YOLOv4æ¨¡å‹...")

    # CPUä¼˜åŒ–è®¾ç½®
    torch.set_num_threads(1)
    torch.backends.cudnn.enabled = False

    try:
        # 1. æ¨¡å‹åˆ›å»ºæµ‹è¯•
        print("\nğŸ“¦ æµ‹è¯•æ¨¡å‹åˆ›å»º...")
        model = YOLO("ultralytics/cfg/models/v4-/yolov4.yaml")
        print(f"âœ… YOLOv4æ¨¡å‹åˆ›å»ºæˆåŠŸï¼")

        # 2. æ¨¡å‹ä¿¡æ¯
        print("\nğŸ“Š æ¨¡å‹ä¿¡æ¯:")
        total_params = sum(p.numel() for p in model.model.parameters())
        print(f"   - æ€»å‚æ•°é‡: {total_params:,}")
        print(f"   - æ¨¡å‹ç±»å‹: {type(model.model).__name__}")
        print(f"   - ç½‘ç»œå±‚æ•°: {len(model.model.model)}")

        # 3. å‰å‘ä¼ æ’­æµ‹è¯•
        print("\nğŸ” æµ‹è¯•å‰å‘ä¼ æ’­...")
        with torch.no_grad():
            # åˆ›å»ºæµ‹è¯•è¾“å…¥ (batch_size=1, channels=3, height=640, width=640)
            test_input = torch.randn(1, 3, 640, 640)
            print(f"   - è¾“å…¥å¼ é‡å½¢çŠ¶: {test_input.shape}")

            # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
            model.model.eval()

            # å‰å‘ä¼ æ’­
            output = model.model(test_input)
            print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼")

            if isinstance(output, (list, tuple)):
                print(f"   - è¾“å‡ºç±»å‹: {type(output)} (é•¿åº¦: {len(output)})")
                for i, out in enumerate(output):
                    if isinstance(out, torch.Tensor):
                        print(f"   - è¾“å‡º{i} å½¢çŠ¶: {out.shape}")
                    else:
                        print(f"   - è¾“å‡º{i} ç±»å‹: {type(out)}")
            else:
                print(f"   - è¾“å‡ºå½¢çŠ¶: {output.shape}")

        # 4. æ£€æµ‹å¤´éªŒè¯
        print("\nğŸ¯ æ£€æµ‹å¤´éªŒè¯...")
        last_layer = model.model.model[-1]
        print(f"   - æ£€æµ‹å¤´ç±»å‹: {type(last_layer).__name__}")
        if hasattr(last_layer, 'nc'):
            print(f"   - ç±»åˆ«æ•°é‡: {last_layer.nc}")
        if hasattr(last_layer, 'nl'):
            print(f"   - æ£€æµ‹å±‚æ•°: {last_layer.nl}")
        if hasattr(last_layer, 'na'):
            print(f"   - æ¯å±‚anchoræ•°: {last_layer.na}")

        print("\nâœ… YOLOv4æ¨¡å‹æµ‹è¯•å®Œæˆï¼æ‰€æœ‰åŠŸèƒ½æ­£å¸¸ï¼")
        return True

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_yolov4_model()
    if success:
        print("\nğŸ‰ YOLOv4å®ç°å®Œå…¨æˆåŠŸï¼")
    else:
        print("\nğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç°é—®é¢˜ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")
```

**ç”¨é€”**: éªŒè¯ YOLOv4 æ¨¡å‹çš„åˆ›å»ºã€å‰å‘ä¼ æ’­å’Œæ£€æµ‹å¤´åŠŸèƒ½ï¼Œç¡®ä¿æ‰€æœ‰ç»„ä»¶æ­£å¸¸å·¥ä½œ

##### 4.2 `debug_parse_detailed.py` - è¯¦ç»†è°ƒè¯•è„šæœ¬

**æ–‡ä»¶å†…å®¹**: ç”¨äºè°ƒè¯• parse_model å‡½æ•°å’Œå±‚ç´¢å¼•é—®é¢˜çš„è¯¦ç»†è°ƒè¯•è„šæœ¬

**ç”¨é€”**: é€å±‚åˆ†æé…ç½®æ–‡ä»¶ï¼Œæ£€æŸ¥å±‚ç´¢å¼•é—®é¢˜ï¼Œå¸®åŠ©å‘ç°å’Œä¿®å¤é…ç½®é”™è¯¯

##### 4.3 `debug_yolov4.py` - YOLOv4 é…ç½®è°ƒè¯•è„šæœ¬

**æ–‡ä»¶å†…å®¹**: ä¸“é—¨ç”¨äºè°ƒè¯• YOLOv4 é…ç½®æ–‡ä»¶å±‚ç´¢å¼•çš„è„šæœ¬

**ç”¨é€”**: åˆ†æ YOLOv4 é…ç½®æ–‡ä»¶çš„å±‚ç»“æ„ï¼Œæ£€æŸ¥å’Œä¿®æ­£å±‚ç´¢å¼•é—®é¢˜ï¼Œæä¾›ä¿®æ­£å»ºè®®

### ğŸ“Š YOLOv4 å®ç°æˆæœ

#### éªŒè¯ç»“æœ

- âœ… **æ¨¡å‹åˆ›å»ºæˆåŠŸ**: YOLOv4 æ¨¡å‹æˆåŠŸåˆ›å»ºï¼Œæ— é”™è¯¯
- âœ… **å‚æ•°ç»Ÿè®¡**: æ€»å‚æ•°é‡ 16,344,157 ä¸ªï¼Œç½‘ç»œå±‚æ•° 23 å±‚
- âœ… **å‰å‘ä¼ æ’­**: è¾“å…¥ [1, 3, 640, 640] â†’ è¾“å‡º [1, 25200, 85]
- âœ… **æ£€æµ‹å¤´éªŒè¯**: YOLOv4Detect æ­£ç¡®è¯†åˆ«ï¼Œæ”¯æŒ 80 ç±»åˆ«ï¼Œ3 ä¸ªæ£€æµ‹å±‚ï¼Œæ¯å±‚ 3 ä¸ª anchor
- âœ… **æ¡†æ¶å…¼å®¹**: å®Œå…¨å…¼å®¹ Ultralytics YOLO æ¡†æ¶ï¼Œæ”¯æŒè®­ç»ƒå’Œæ¨ç†

#### æŠ€æœ¯ç‰¹æ€§

1. **CSPDarknet53 éª¨å¹²ç½‘ç»œ**: ä½¿ç”¨ CSP (Cross Stage Partial) æ¶æ„æé«˜æ¢¯åº¦æµ
2. **SPP + PANet é¢ˆéƒ¨ç½‘ç»œ**: å¤šå°ºåº¦ç‰¹å¾èåˆå’Œè·¯å¾„èšåˆ
3. **å¤šå°ºåº¦æ£€æµ‹**: æ”¯æŒ P3/8ã€P4/16ã€P5/32 ä¸‰ä¸ªæ£€æµ‹å°ºåº¦
4. **Anchor Boxes**: æ¯ä¸ªæ£€æµ‹å±‚ä½¿ç”¨ 3 ä¸ªé¢„å®šä¹‰çš„ anchor boxes
5. **æ¨¡å—åŒ–è®¾è®¡**: åŸºäºç°æœ‰æ¡†æ¶ç»„ä»¶æ„å»ºï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•

#### è§£å†³çš„é—®é¢˜

1. **å±‚ç´¢å¼•è¶…å‡ºèŒƒå›´**: åŸå§‹ yaml é…ç½®ä¸­çš„å±‚ç´¢å¼• [33, 37, 41] è¶…å‡ºå®é™…å±‚æ•°ï¼Œä¿®æ­£ä¸º [15, 18, 21]
2. **ç¼ºå°‘æ¡†æ¶å±æ€§**: YOLOv4Detect ç¼ºå°‘ exportã€formatã€dynamic å±æ€§ï¼Œå·²æ·»åŠ 
3. **å‚æ•°æ ¼å¼ä¸åŒ¹é…**: è°ƒæ•´ YOLOv4Detect åˆå§‹åŒ–å‚æ•°é¡ºåºä¸æ¡†æ¶æœŸæœ›ä¸€è‡´
4. **CSPBlock æ¨¡å—ç¼ºå¤±**: åŸºäºç°æœ‰ BottleneckCSP å®ç° CSPBlock æ¨¡å—

#### è®­ç»ƒéªŒè¯

å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿›è¡Œè®­ç»ƒæµ‹è¯•ï¼š

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd d:\Code\pycode\yolo-try

# è¿è¡Œ YOLOv4 æ¨¡å‹æµ‹è¯•
python test_yolov4.py

# è¿è¡Œè®­ç»ƒè„šæœ¬æµ‹è¯•
python train.py --data coco.yaml --model ultralytics/cfg/models/v4-/yolov4.yaml --epochs 1
```

---

## ğŸ”¥ YOLOv2 å®ç°ä¿®æ”¹è®°å½•

### ğŸ“‹ YOLOv2 ä¿®æ”¹æ–‡ä»¶æ¸…å•

#### 1. æ ¸å¿ƒæ¨¡å—å®ç°

##### 1.1 `ultralytics/nn/modules/block.py` - æ·»åŠ  Passthrough æ¨¡å—

**ä¿®æ”¹ä½ç½®**: ç¬¬ 1950-2007 è¡Œ
**ä¿®æ”¹å†…å®¹**: æ–°å¢ Passthrough ç±»

```
# YOLOv2 Passthrough layer implementation
class Passthrough(nn.Module):
    """
    Passthrough module for YOLOv2 feature reorganization.

    This module implements the passthrough layer used in YOLOv2 to reorganize
    high-resolution feature maps to be concatenated with low-resolution semantic features.
    It rearranges spatial information into channels by taking every 2x2 block and
    stacking them in the channel dimension.

    Methods:
        forward: Reorganizes the input tensor by rearranging spatial information into channels.

    Examples:
        >>> import torch
        >>> passthrough = Passthrough()
        >>> x = torch.randn(1, 256, 26, 26)  # High-res features from earlier layer
        >>> output = passthrough(x)  # Output: (1, 1024, 13, 13)
        >>> print(f"Input: {x.shape}, Output: {output.shape}")
    """

    def __init__(self):
        """Initialize the Passthrough module."""
        super().__init__()

    def forward(self, x):
        """
        Reorganize feature map by rearranging spatial information into channels.

        Args:
            x (torch.Tensor): Input feature map of shape (batch, channels, height, width)

        Returns:
            torch.Tensor: Reorganized feature map with spatial info moved to channels
                         Shape: (batch, channels*4, height//2, width//2)
        """
        batch_size, channels, height, width = x.shape

        # Ensure dimensions are even for proper reshaping
        assert height % 2 == 0 and width % 2 == 0, \
            f"Height ({height}) and width ({width}) must be even for passthrough operation"

        # Reshape to separate odd and even positions
        # (batch, channels, height, width) -> (batch, channels, height//2, 2, width//2, 2)
        x = x.view(batch_size, channels, height // 2, 2, width // 2, 2)

        # Permute to group the 2x2 spatial blocks
        # (batch, channels, height//2, 2, width//2, 2) -> (batch, channels, 2, 2, height//2, width//2)
        x = x.permute(0, 1, 3, 5, 2, 4).contiguous()

        # Reshape to stack the 2x2 blocks in the channel dimension
        # (batch, channels, 2, 2, height//2, width//2) -> (batch, channels*4, height//2, width//2)
        x = x.view(batch_size, channels * 4, height // 2, width // 2)

        return x
```

**ç”¨é€”**: å®ç° YOLOv2 çš„ Passthrough å±‚ï¼Œå°†é«˜åˆ†è¾¨ç‡ç‰¹å¾é‡ç»„ä»¥ä¸ä½åˆ†è¾¨ç‡è¯­ä¹‰ç‰¹å¾èåˆï¼Œé€šè¿‡ç©ºé—´åˆ°é€šé“çš„é‡æ’æé«˜æ£€æµ‹ç²¾åº¦

##### 1.2 `ultralytics/nn/modules/head.py` - æ·»åŠ  YOLOv2Detect æ£€æµ‹å¤´

**ä¿®æ”¹ä½ç½®**: ç¬¬ 704-827 è¡Œ
**ä¿®æ”¹å†…å®¹**: æ–°å¢ YOLOv2Detect ç±»

```
class YOLOv2Detect(nn.Module):
    """
    YOLOv2 detection head for object detection.

    This detection head implements YOLOv2's approach using anchor boxes for object detection.
    Unlike YOLOv1's grid-based approach, YOLOv2 uses predefined anchor boxes at each grid cell
    to predict bounding boxes with better accuracy.

    Attributes:
        nc (int): Number of classes.
        anchors (list): List of anchor box dimensions.
        na (int): Number of anchors per grid cell.
        grid_size (int): Size of the detection grid.
        stride (torch.Tensor): Stride tensor for compatibility.
        nl (int): Number of detection layers.

    Methods:
        forward: Forward pass through YOLOv2 detection head.

    Examples:
        >>> anchors = [[1.3221, 1.73145], [3.19275, 4.00944], [5.05587, 8.09892]]
        >>> detect_head = YOLOv2Detect(anchors=anchors, nc=80)
        >>> x = torch.randn(1, 13, 13, 425)  # (batch, height, width, channels)
        >>> output = detect_head([x])
    """

    def __init__(self, anchors=None, nc=80):
        """
        Initialize YOLOv2 detection head.

        Args:
            anchors (list, optional): List of anchor box dimensions [[w1,h1], [w2,h2], ...]
                                     If None, default anchors will be used
            nc (int): Number of classes (default: 80 for COCO)
        """
        super().__init__()
        self.nc = nc  # number of classes

        # Default YOLOv2 anchors if not provided
        if anchors is None:
            anchors = [[1.3221, 1.73145], [3.19275, 4.00944], [5.05587, 8.09892],
                      [9.47112, 4.84053], [11.2364, 10.0071]]

        self.anchors = anchors  # anchor boxes
        self.na = len(anchors)  # number of anchors

        # Convert anchors to tensor
        self.register_buffer('anchor_grid', torch.tensor(anchors, dtype=torch.float32).view(1, self.na, 1, 1, 2))

        # For compatibility with the framework
        self.stride = torch.tensor([32.0])  # YOLOv2 typically uses 32x downsampling
        self.nl = 1  # number of detection layers
        self.grid_size = 13  # typical YOLOv2 grid size for 416x416 input
        self.reg_max = 1  # for compatibility with loss functions
```

**ç”¨é€”**: å®ç° YOLOv2 æ£€æµ‹å¤´ï¼Œæ”¯æŒ anchor boxes æœºåˆ¶ï¼Œæä¾›æ¯” YOLOv1 æ›´å‡†ç¡®çš„è¾¹ç•Œæ¡†é¢„æµ‹

#### 2. æ¨¡å—å¯¼å…¥å’Œæ³¨å†Œ

##### 2.1 `ultralytics/nn/modules/__init__.py` - æ·»åŠ æ¨¡å—å¯¼å…¥

**ä¿®æ”¹ä½ç½®**:

- ç¬¬ 58 è¡Œ: æ·»åŠ  Passthrough å¯¼å…¥åˆ° block æ¨¡å—å¯¼å…¥åˆ—è¡¨
- ç¬¬ 75 è¡Œ: æ·»åŠ  YOLOv2Detect å¯¼å…¥åˆ° head æ¨¡å—å¯¼å…¥åˆ—è¡¨
- ç¬¬ 157 è¡Œ: åœ¨ **all** åˆ—è¡¨ä¸­æ·»åŠ  "YOLOv2Detect"
- ç¬¬ 178 è¡Œ: åœ¨ **all** åˆ—è¡¨ä¸­æ·»åŠ  "Passthrough"

**ç”¨é€”**: å°†æ–°æ¨¡å—æ³¨å†Œåˆ°æ¡†æ¶ä¸­ï¼Œä½¿å…¶å¯ä»¥åœ¨ YAML é…ç½®ä¸­ä½¿ç”¨

##### 2.2 `ultralytics/nn/tasks.py` - æ·»åŠ æ¨¡å—æ”¯æŒ

**ä¿®æ”¹ä½ç½®**:

- ç¬¬ 62 è¡Œ: æ·»åŠ  Passthrough å¯¼å…¥
- ç¬¬ 63 è¡Œ: æ·»åŠ  YOLOv2Detect å¯¼å…¥
- ç¬¬ 81 è¡Œ: æ·»åŠ  YOLOv2Loss å¯¼å…¥
- ç¬¬ 398-406 è¡Œ: ä¿®æ”¹ init_criterion æ–¹æ³•æ·»åŠ  YOLOv2 æ”¯æŒ
- ç¬¬ 1082 è¡Œ: æ·»åŠ  YOLOv2Detect ç‰¹æ®Šå¤„ç†
- ç¬¬ 1227 è¡Œ: æ·»åŠ  guess_model_task ä¸­çš„ YOLOv2Detect è¯†åˆ«

**ç”¨é€”**: æ”¯æŒ YOLOv2 æ¨¡å‹çš„è§£æå’ŒæŸå¤±å‡½æ•°é€‰æ‹©ï¼Œä½¿æ¡†æ¶èƒ½å¤Ÿæ­£ç¡®è¯†åˆ«å’Œå¤„ç† YOLOv2 æ£€æµ‹å¤´

#### 3. æŸå¤±å‡½æ•°å®ç°

##### 3.1 `ultralytics/utils/loss.py` - æ·»åŠ  YOLOv2Loss æŸå¤±å‡½æ•°

**ä¿®æ”¹ä½ç½®**: ç¬¬ 946-1116 è¡Œ
**ä¿®æ”¹å†…å®¹**: æ–°å¢ YOLOv2Loss ç±»

```
class YOLOv2Loss:
    """
    YOLOv2 loss function for object detection with anchor boxes.

    This loss function implements YOLOv2's approach using anchor boxes for object detection.
    It computes coordinate loss, confidence loss, and class loss.

    Attributes:
        nc (int): Number of classes.
        na (int): Number of anchors.
        anchors (torch.Tensor): Anchor boxes.
        lambda_coord (float): Weight for coordinate loss.
        lambda_noobj (float): Weight for no-object loss.
        lambda_class (float): Weight for classification loss.
    """

    def __init__(self, model):
        """Initialize YOLOv2 loss with model."""
        device = next(model.parameters()).device
        h = model.args  # hyperparameters
        m = model.model[-1]  # YOLOv2Detect() module

        self.device = device
        self.hyp = h
        self.nc = m.nc  # number of classes
        self.na = m.na  # number of anchors
        self.anchors = m.anchor_grid.clone()  # anchor boxes

        # Loss weights (YOLOv2 paper values)
        self.lambda_coord = 5.0  # weight for coordinate loss
        self.lambda_noobj = 0.5  # weight for no-object loss
        self.lambda_class = 1.0  # weight for classification loss

        # Loss functions
        self.mse = nn.MSELoss(reduction='sum')
        self.bce = nn.BCEWithLogitsLoss(reduction='sum')
```

**ç”¨é€”**: å®ç° YOLOv2 anchor-based æŸå¤±å‡½æ•°ï¼ŒåŒ…å«åæ ‡æŸå¤±ã€ç½®ä¿¡åº¦æŸå¤±å’Œåˆ†ç±»æŸå¤±ï¼Œæ”¯æŒå¤šå°ºåº¦ anchor é¢„æµ‹

#### 4. é…ç½®æ–‡ä»¶

##### 4.1 `ultralytics/cfg/models/v2-/yolov2.yaml` - YOLOv2 æ¨¡å‹é…ç½®

**ä¿®æ”¹ä½ç½®**: å¤šä¸ªä½ç½®ä¿®æ­£
**ä¿®æ”¹å†…å®¹**:

```
# YOLOv2 (YOLO9000) ç½‘ç»œç»“æ„é…ç½®æ–‡ä»¶
# å‚è€ƒ: YOLO9000: Better, Faster, Stronger

# å‚æ•°é…ç½®
nc: 80 # COCOæ•°æ®é›†80ä¸ªç±»åˆ«
depth_multiple: 1.0
width_multiple: 1.0
anchors: # YOLOv2ä½¿ç”¨çš„å…ˆéªŒæ¡†å°ºå¯¸(COCOæ•°æ®é›†)
  - [1.3221, 1.73145]
  - [3.19275, 4.00944]
  - [5.05587, 8.09892]
  - [9.47112, 4.84053]
  - [11.2364, 10.0071]

# Darknet-19 éª¨å¹²ç½‘ç»œ
backbone:
  # [from, number, module, args]
  - [-1, 1, Conv, [32, 3, 1, 1]] # 0
  - [-1, 1, nn.MaxPool2d, [2, 2]] # 1-P1/2  ä¿®æ­£ï¼šnn.MaxPool -> nn.MaxPool2d
  - [-1, 1, Conv, [64, 3, 1, 1]] # 2
  - [-1, 1, nn.MaxPool2d, [2, 2]] # 3-P2/4  ä¿®æ­£ï¼šnn.MaxPool -> nn.MaxPool2d
  # ... å…¶ä»–å±‚

# YOLOv2 æ£€æµ‹å¤´
head:
  - [-1, 1, Conv, [1024, 3, 1, 1]] # 23
  - [-1, 1, Conv, [1024, 3, 1, 1]] # 24

  # Passthroughå±‚ (ç‰¹å¾é‡ç»„ï¼Œå°†é«˜åˆ†è¾¨ç‡ç‰¹å¾ä¸è¯­ä¹‰ç‰¹å¾èåˆ)
  - [16, 1, Passthrough, []] # 25 ä»ç¬¬16å±‚è·å–ç‰¹å¾

  - [[24, 25], 1, Concat, [1]] # 26 ç‰¹å¾æ‹¼æ¥
  - [-1, 1, Conv, [1024, 3, 1, 1]] # 27 è‡ªåŠ¨æ¨å¯¼è¾“å…¥é€šé“æ•°

  # æ£€æµ‹å±‚: è¾“å‡ºç»´åº¦ä¸º (batch, height, width, anchors*(5+classes))
  # å¯¹äºCOCO: 5ä¸ªanchor * (5+80) = 425
  - [-1, 1, Conv, [425, 1, 1, 0]] # 28

  # YOLOv2æ£€æµ‹å±‚
  - [[28], 1, YOLOv2Detect, []] # 29
```

**ä¿®å¤é—®é¢˜**:

1. `nn.MaxPool` â†’ `nn.MaxPool2d` (ç¬¬ 21, 23, 25 è¡Œ)
2. ç®€åŒ–è¾“å‡ºé€šé“é…ç½®ï¼Œç§»é™¤å¤æ‚è¡¨è¾¾å¼
3. YOLOv2Detect å‚æ•°ç®€åŒ–

**ç”¨é€”**: å®šä¹‰å®Œæ•´çš„ YOLOv2 ç½‘ç»œæ¶æ„ï¼ŒåŒ…æ‹¬ Darknet-19 backbone å’Œ anchor-based æ£€æµ‹å¤´

#### 5. è®­ç»ƒè„šæœ¬æµ‹è¯•

##### 5.1 `train.py` - YOLOv2 æ¨¡å‹æµ‹è¯•è„šæœ¬

**ä¿®æ”¹ä½ç½®**: æ•´ä¸ªæ–‡ä»¶é‡æ„
**ä¿®æ”¹å†…å®¹**:

```
from ultralytics import YOLO
import torch

# CPUå†…å­˜ä¼˜åŒ–è®¾ç½®
torch.set_num_threads(1)  # å•çº¿ç¨‹å‡å°‘å†…å­˜
torch.backends.cudnn.enabled = False

print("ğŸš€ YOLOv2 æ¨¡å‹æ„å»ºæµ‹è¯•...")

# æ„å»º YOLOv2 æ¨¡å‹
model = YOLO("yolov2.yaml")
print(f"âœ… YOLOv2 æ¨¡å‹æ„å»ºæˆåŠŸï¼")
print(f"ğŸ“Š æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.model.parameters()):,}")

# æµ‹è¯•å‰å‘ä¼ æ’­
print("\nğŸ” æµ‹è¯•å‰å‘ä¼ æ’­...")
with torch.no_grad():
    # åˆ›å»ºæµ‹è¯•è¾“å…¥ (batch_size=1, channels=3, height=416, width=416)
    test_input = torch.randn(1, 3, 416, 416)
    print(f"ğŸ“ è¾“å…¥å¼ é‡å½¢çŠ¶: {test_input.shape}")

    # å‰å‘ä¼ æ’­
    try:
        output = model.model(test_input)
        print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼")
        if isinstance(output, list):
            for i, out in enumerate(output):
                print(f"ğŸ“Š è¾“å‡º{i} å½¢çŠ¶: {out.shape}")
        else:
            print(f"ğŸ“Š è¾“å‡ºå½¢çŠ¶: {output.shape}")
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")

print("\nâœ… YOLOv2 æ¨¡å‹æµ‹è¯•å®Œæˆï¼")
```

**ç”¨é€”**: éªŒè¯ YOLOv2 æ¨¡å‹æ„å»ºå’Œå‰å‘ä¼ æ’­åŠŸèƒ½

---

## ğŸ¯ YOLOv2 å®ç°çŠ¶æ€

### âœ… å·²å®ŒæˆåŠŸèƒ½

1. **å®Œæ•´çš„ YOLOv2 æ¶æ„** - Darknet-19 backbone + anchor-based æ£€æµ‹å¤´
2. **Passthrough å±‚** - å®ç°ç‰¹å¾é‡ç»„å’Œå¤šå°ºåº¦èåˆ
3. **YOLOv2Detect æ£€æµ‹å¤´** - æ”¯æŒ 5 ä¸ª anchor boxes
4. **YOLOv2Loss æŸå¤±å‡½æ•°** - anchor-based æŸå¤±è®¡ç®—
5. **æ¡†æ¶å…¼å®¹æ€§** - å®Œå…¨é›†æˆåˆ° Ultralytics æ¡†æ¶ä¸­
6. **æ¨¡å‹æ„å»º** - æˆåŠŸæ„å»º 53,296,896 å‚æ•°çš„æ¨¡å‹

### ğŸ”§ å·²çŸ¥é—®é¢˜

1. **é€šé“æ•°ä¸åŒ¹é…**: ç¬¬ 27 å±‚æœŸæœ› 1536 é€šé“ï¼Œå®é™…è¾“å…¥ 3072 é€šé“
   - **åŸå› **: Passthrough(512â†’2048) + Conv24(1024) = 3072 é€šé“
   - **çŠ¶æ€**: éœ€è¦ä¿®å¤é…ç½®æˆ–æ¡†æ¶é€‚é…

### ğŸ“Š éªŒè¯ç»“æœ

- âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸï¼ˆ53.3M å‚æ•°ï¼‰
- âœ… ç½‘ç»œæ¶æ„æ­£ç¡®ï¼ˆ77 å±‚ï¼‰
- âœ… Passthrough å±‚åŠŸèƒ½æ­£å¸¸
- âœ… YOLOv2Detect æ£€æµ‹å¤´åˆ›å»ºæˆåŠŸ
- âŒ å‰å‘ä¼ æ’­å­˜åœ¨é€šé“ç»´åº¦é—®é¢˜

### ğŸ”§ å…³é”®æŠ€æœ¯è¦ç‚¹

1. **Passthrough å±‚è®¾è®¡** - ç©ºé—´åˆ°é€šé“çš„é‡æ’æ“ä½œï¼Œå°† 26Ã—26Ã—512 â†’ 13Ã—13Ã—2048
2. **Anchor boxes æœºåˆ¶** - 5 ä¸ªé¢„å®šä¹‰ anchor ç”¨äºæ›´å‡†ç¡®çš„è¾¹ç•Œæ¡†é¢„æµ‹
3. **å¤šå°ºåº¦ç‰¹å¾èåˆ** - ç»“åˆé«˜åˆ†è¾¨ç‡ç»†èŠ‚å’Œä½åˆ†è¾¨ç‡è¯­ä¹‰ä¿¡æ¯
4. **æŸå¤±å‡½æ•°é€‚é…** - anchor-based åæ ‡å›å½’å’Œ IoU-aware confidence é¢„æµ‹

---

## ğŸ“‹ ä¿®æ”¹æ–‡ä»¶æ¸…å•

### 1. æ ¸å¿ƒæ¨¡å—å®ç°

#### 1.1 `ultralytics/nn/modules/block.py` - æ·»åŠ  Reshape æ¨¡å—

**ä¿®æ”¹ä½ç½®**: ç¬¬ 1919-1949 è¡Œ
**ä¿®æ”¹å†…å®¹**: æ–°å¢ Reshape ç±»

```
class Reshape(nn.Module):
    """
    Reshape module for tensor reshaping operations.

    This module reshapes the input tensor to the specified target shape. It's commonly used
    in YOLO architectures to reshape feature maps before detection heads.
    """

    def __init__(self, *args):
        """Initialize the Reshape module with target shape dimensions."""
        super().__init__()
        self.shape = args

    def forward(self, x):
        """Reshape input tensor to target shape."""
        batch_size = x.shape[0]
        return x.view(batch_size, *self.shape)
```

**ç”¨é€”**: ç”¨äºå°† YOLOv1 çš„å±•å¹³ç‰¹å¾é‡å¡‘ä¸º 7x7x30 çš„è¾“å‡ºæ ¼å¼

#### 1.2 `ultralytics/nn/modules/head.py` - æ·»åŠ  YOLOv1Detect æ£€æµ‹å¤´

**ä¿®æ”¹ä½ç½®**: ç¬¬ 627-699 è¡Œ
**ä¿®æ”¹å†…å®¹**: æ–°å¢ YOLOv1Detect ç±»

```
class YOLOv1Detect(nn.Module):
    """
    YOLOv1 detection head for the original YOLO architecture.

    This detection head implements the original YOLOv1 approach where the network
    predicts B bounding boxes and class probabilities for each grid cell.
    """

    def __init__(self, nc=80):
        """Initialize YOLOv1 detection head with number of classes."""
        super().__init__()
        self.nc = nc  # number of classes
        self.grid_size = 7  # 7x7 grid
        self.num_boxes = 2  # 2 bounding boxes per cell

        # Add attributes for compatibility with loss function
        self.stride = torch.tensor([32.0])  # YOLOv1 uses single scale with 32x downsample
        self.reg_max = 1  # YOLOv1 doesn't use DFL, set to 1 for compatibility
        self.nl = 1  # number of detection layers (YOLOv1 has only one)

    def forward(self, x):
        """Forward pass through YOLOv1 detection head."""
        if self.training:
            return x
        else:
            # æ¨ç†æ—¶çš„å¤„ç†é€»è¾‘
            batch_size, S, S, features = x.shape
            # ... å¤„ç†é€»è¾‘
            return output
```

**ç”¨é€”**: å®ç° YOLOv1 åŸå§‹æ£€æµ‹å¤´ï¼Œæ”¯æŒ 7x7 ç½‘æ ¼é¢„æµ‹ï¼Œæ¯ä¸ªç½‘æ ¼é¢„æµ‹ 2 ä¸ªè¾¹ç•Œæ¡†

### 2. æ¨¡å—å¯¼å…¥å’Œæ³¨å†Œ

#### 2.1 `ultralytics/nn/modules/__init__.py` - æ·»åŠ æ¨¡å—å¯¼å…¥

**ä¿®æ”¹ä½ç½®**:

- ç¬¬ 78 è¡Œ: æ·»åŠ  Reshape å¯¼å…¥åˆ° block æ¨¡å—å¯¼å…¥åˆ—è¡¨
- ç¬¬ 81 è¡Œ: æ·»åŠ  YOLOv1Detect å¯¼å…¥åˆ° head æ¨¡å—å¯¼å…¥åˆ—è¡¨
- ç¬¬ 156 è¡Œ: åœ¨ **all** åˆ—è¡¨ä¸­æ·»åŠ  "YOLOv1Detect"
- ç¬¬ 177 è¡Œ: åœ¨ **all** åˆ—è¡¨ä¸­æ·»åŠ  "Reshape"

**ä¿®æ”¹å†…å®¹**:

```
# ç¬¬78è¡Œ - blockæ¨¡å—å¯¼å…¥éƒ¨åˆ†ä¿®æ”¹
from .block import (
    C1,
    C2,
    C3,
    C2f,
    C2fAttn,
    C3TR,
    C3Ghost,
    C3x,
    RepC3,
    GhostBottleneck,
    Bottleneck,
    BottleneckCSP,
    Proto,
    HGStem,
    HGBlock,
    SPP,
    SPPF,
    C2fCIB,
    C2fPSA,
    C2PSA,
    RepNCSPELAN4,
    ADown,
    SPPELAN,
    CBFuse,
    CBLinear,
    RepVGG,
    CIB,
    PSA,
    SCDown,
    Reshape,  # æ–°å¢
)

# ç¬¬81è¡Œ - headæ¨¡å—å¯¼å…¥éƒ¨åˆ†ä¿®æ”¹
from .head import OBB, Classify, Detect, Pose, RTDETRDecoder, Segment, WorldDetect, v10Detect, YOLOv1Detect

# ç¬¬156è¡Œ - __all__åˆ—è¡¨ä¸­æ·»åŠ YOLOv1Detect
__all__ = (
    "Conv",
    "Conv2",
    "LightConv",
    "RepConv",
    "DWConv",
    "DWConvTranspose2d",
    "ConvTranspose",
    "Focus",
    "GhostConv",
    "ChannelAttention",
    "SpatialAttention",
    "CBAM",
    "Concat",
    "TransformerLayer",
    "TransformerBlock",
    "MLPBlock",
    "LayerNorm2d",
    "DFL",
    "HGStem",
    "HGBlock",
    "SPP",
    "SPPF",
    "C1",
    "C2",
    "C3",
    "C2f",
    "C2fAttn",
    "C3TR",
    "C3Ghost",
    "C3x",
    "RepC3",
    "Bottleneck",
    "BottleneckCSP",
    "Proto",
    "Detect",
    "WorldDetect",
    "Segment",
    "Pose",
    "Classify",
    "OBB",
    "RTDETRDecoder",
    "v10Detect",
    "YOLOv1Detect",  # æ–°å¢
    "ImagePoolingAttn",
    "ContrastiveHead",
    "BNContrastiveHead",
    "RepNCSPELAN4",
    "ADown",
    "SPPELAN",
    "CBFuse",
    "CBLinear",
    "C2fCIB",
    "C2fPSA",
    "C2PSA",
    "RepVGG",
    "CIB",
    "PSA",
    "SCDown",
    "Reshape",  # ç¬¬177è¡Œ - æ–°å¢
)
```

**ç”¨é€”**: å°†æ–°æ¨¡å—æ³¨å†Œåˆ°æ¡†æ¶ä¸­ï¼Œä½¿å…¶å¯ä»¥åœ¨ YAML é…ç½®ä¸­ä½¿ç”¨

#### 2.2 `ultralytics/nn/tasks.py` - æ·»åŠ æ¨¡å—æ”¯æŒ

**ä¿®æ”¹ä½ç½®**:

- ç¬¬ 59 è¡Œ: æ·»åŠ  YOLOv1Detect å¯¼å…¥
- ç¬¬ 77 è¡Œ: æ·»åŠ  YOLOv1Loss å¯¼å…¥
- ç¬¬ 393-396 è¡Œ: ä¿®æ”¹ init_criterion æ–¹æ³•
- ç¬¬ 1065 è¡Œ: æ·»åŠ  YOLOv1Detect ç‰¹æ®Šå¤„ç†
- ç¬¬ 1203 è¡Œ: æ·»åŠ  guess_model_task ä¸­çš„ YOLOv1Detect è¯†åˆ«

**ä¿®æ”¹å†…å®¹**:

```
# ç¬¬59è¡Œ - æ¨¡å—å¯¼å…¥éƒ¨åˆ†
from ultralytics.nn.modules import (
    AIFI,
    C1,
    C2,
    C3,
    C2f,
    C2fAttn,
    C3TR,
    C3Ghost,
    C3x,
    SPP,
    SPPF,
    Bottleneck,
    BottleneckCSP,
    C2fCIB,
    C2fPSA,
    C2PSA,
    Classify,
    Concat,
    Conv,
    Conv2,
    ConvTranspose,
    Detect,
    DFL,
    DWConv,
    DWConvTranspose2d,
    Focus,
    GhostBottleneck,
    GhostConv,
    HGBlock,
    HGStem,
    Pose,
    RepC3,
    RepConv,
    RTDETRDecoder,
    Segment,
    WorldDetect,
    v10Detect,
    YOLOv1Detect,  # æ–°å¢
    RepNCSPELAN4,
    ADown,
    SPPELAN,
    CBFuse,
    CBLinear,
    OBB,
    RepVGG,
    CIB,
    PSA,
    SCDown,
)

# ç¬¬77è¡Œ - æŸå¤±å‡½æ•°å¯¼å…¥éƒ¨åˆ†
from ultralytics.utils.loss import (
    BboxLoss,
    DETRLoss,
    E2EDetectLoss,
    KeypointLoss,
    OBBLoss,
    SegmentationLoss,
    v8DetectionLoss,
    v8OBBLoss,
    v8PoseLoss,
    v8SegmentationLoss,
    v10DetectLoss,
    YOLOv1Loss,  # æ–°å¢
)

# ç¬¬393-396è¡Œ - init_criterionæ–¹æ³•ä¿®æ”¹
def init_criterion(self):
    """Initialize the loss criterion for the DetectionModel."""
    m = self.model[-1]  # last layer
    if isinstance(m, YOLOv1Detect):  # æ–°å¢åˆ¤æ–­
        return YOLOv1Loss(self)
    return E2EDetectLoss(self) if getattr(self, "end2end", False) else v8DetectionLoss(self)

# ç¬¬1065è¡Œ - parse_modelå‡½æ•°ä¸­YOLOv1Detectç‰¹æ®Šå¤„ç†
if m in {Concat, Detect, WorldDetect, v10Detect, Segment, Pose, OBB, Classify, RTDETRDecoder}:
    args.append([ch[x] for x in f])
    if m is Segment:
        args[2] = make_divisible(min(args[2], max_channels) * width, 8)
    elif m in {Detect, WorldDetect, v10Detect}:
        args[1] = make_divisible(min(args[1], max_channels // 2) * width, 8)
else:
    c2 = make_divisible(min(c2, max_channels) * width, 8) if c2 != no_bias_keys else c2

# æ–°å¢çš„YOLOv1Detectç‰¹æ®Šå¤„ç†
if m is YOLOv1Detect:
    # YOLOv1Detect doesn't need channel list, just use the nc parameter
    pass

# ç¬¬1203è¡Œ - guess_model_taskå‡½æ•°ä¸­çš„è¯†åˆ«
def guess_model_task(model):
    """Guess model task from model architecture."""
    def model_stride(model):
        """Return model stride."""
        try:
            return max(int(model.stride.max()), 32) if hasattr(model, "stride") else 32
        except Exception:
            return 32

    def model_class_count(model):
        """Return the number of model classes if available."""
        for x in model.modules():
            if isinstance(x, (Detect, WorldDetect, v10Detect, YOLOv1Detect)):  # æ–°å¢ YOLOv1Detect
                return x.nc
        return 1000

    # Model YAML
    if isinstance(model, dict):
        with contextlib.suppress(Exception):
            return cfg2task(model)

    # PyTorch model
    for x in model.modules():
        if isinstance(x, (Detect, WorldDetect, v10Detect, YOLOv1Detect)):  # æ–°å¢ YOLOv1Detect
            return "detect"
        elif isinstance(x, Segment):
            return "segment"
        elif isinstance(x, Classify):
            return "classify"
        elif isinstance(x, Pose):
            return "pose"
        elif isinstance(x, OBB):
            return "obb"
        elif isinstance(x, RTDETRDecoder):  # Real-Time DETR
            return "detect"

    # Guess from model filename
    if isinstance(model, (str, Path)):
        model = Path(model)
        if "-seg" in model.stem or "segment" in model.parts:
            return "segment"
        elif "-cls" in model.stem or "classify" in model.parts:
            return "classify"
        elif "-pose" in model.stem or "pose" in model.parts:
            return "pose"
        elif "-obb" in model.stem or "obb" in model.parts:
            return "obb"

    # Unable to determine task from model
    LOGGER.warning(
        "WARNING âš ï¸ Model task could not be automatically determined. "
        "Explicitly define model task like 'task=detect', 'task=segment', 'task=classify','task=pose', or 'task=obb'."
    )
    return "detect"  # assume detect
```

**ç”¨é€”**: æ”¯æŒ YOLOv1 æ¨¡å‹çš„è§£æå’ŒæŸå¤±å‡½æ•°é€‰æ‹©ï¼Œä½¿æ¡†æ¶èƒ½å¤Ÿæ­£ç¡®è¯†åˆ«å’Œå¤„ç† YOLOv1 æ£€æµ‹å¤´

### 3. æŸå¤±å‡½æ•°å®ç°

#### 3.1 `ultralytics/utils/loss.py` - æ·»åŠ  YOLOv1Loss æŸå¤±å‡½æ•°

**ä¿®æ”¹ä½ç½®**: ç¬¬ 751-944 è¡Œ
**ä¿®æ”¹å†…å®¹**: æ–°å¢ YOLOv1Loss ç±»

```
class YOLOv1Loss:
    """YOLOv1 loss function for the original YOLO architecture."""

    def __init__(self, model):
        """Initialize YOLOv1 loss with model."""
        device = next(model.parameters()).device
        h = model.args  # hyperparameters
        m = model.model[-1]  # YOLOv1Detect() module

        self.device = device
        self.hyp = h
        self.nc = m.nc  # number of classes
        self.lambda_coord = 5.0  # weight for coordinate loss
        self.lambda_noobj = 0.5  # weight for no-object loss

        # Loss functions
        self.mse = nn.MSELoss(reduction='sum')
        self.bce = nn.BCELoss(reduction='sum')

    def __call__(self, preds, batch):
        """Calculate YOLOv1 loss."""
        device = preds.device
        batch_size = preds.shape[0]

        # Ground truth processing
        gt_boxes = batch['bboxes']  # (batch_size, num_objects, 4) - x1,y1,x2,y2 format
        gt_cls = batch['cls']  # (batch_size, num_objects, 1)

        # Initialize target tensor: (batch_size, 7, 7, 30)
        # 30 = 2*5 (ä¸¤ä¸ªè¾¹ç•Œæ¡†æ¯ä¸ª5ä¸ªå€¼: x,y,w,h,confidence) + 20 (classes)
        targets = torch.zeros(batch_size, 7, 7, 30, device=device)

        # Process ground truth
        for b in range(batch_size):
            valid_mask = gt_cls[b].squeeze(-1) >= 0  # æœ‰æ•ˆçš„ç›®æ ‡
            if not valid_mask.any():
                continue

            valid_boxes = gt_boxes[b][valid_mask]  # (num_valid, 4)
            valid_cls = gt_cls[b][valid_mask].long()  # (num_valid, 1)

            for box, cls in zip(valid_boxes, valid_cls):
                cls = cls.item()
                if cls < 0 or cls >= self.nc:
                    continue

                # Convert box format from x1,y1,x2,y2 to center_x,center_y,w,h (normalized)
                x1, y1, x2, y2 = box
                center_x = (x1 + x2) / 2.0
                center_y = (y1 + y2) / 2.0
                width = x2 - x1
                height = y2 - y1

                # Get grid cell indices
                grid_x = int(center_x * 7)
                grid_y = int(center_y * 7)
                grid_x = min(max(grid_x, 0), 6)
                grid_y = min(max(grid_y, 0), 6)

                # Set target values
                # ç¬¬ä¸€ä¸ªè¾¹ç•Œæ¡† (0-4)
                targets[b, grid_y, grid_x, 0] = center_x * 7 - grid_x  # relative x
                targets[b, grid_y, grid_x, 1] = center_y * 7 - grid_y  # relative y
                targets[b, grid_y, grid_x, 2] = torch.sqrt(width)  # sqrt(w)
                targets[b, grid_y, grid_x, 3] = torch.sqrt(height)  # sqrt(h)
                targets[b, grid_y, grid_x, 4] = 1.0  # confidence

                # ç¬¬äºŒä¸ªè¾¹ç•Œæ¡†è®¾ä¸ºç›¸åŒ (5-9) - YOLOv1è®­ç»ƒæ—¶ä¸¤ä¸ªæ¡†åˆå§‹ç›¸åŒ
                targets[b, grid_y, grid_x, 5:10] = targets[b, grid_y, grid_x, 0:5]

                # ç±»åˆ«æ¦‚ç‡ (10-29)
                targets[b, grid_y, grid_x, 10 + cls] = 1.0

        # Calculate loss components
        coord_loss = 0.0
        conf_loss = 0.0
        noobj_loss = 0.0
        class_loss = 0.0

        # éå†æ¯ä¸ªç½‘æ ¼å•å…ƒ
        for i in range(7):
            for j in range(7):
                for b in range(batch_size):
                    # é¢„æµ‹å€¼
                    pred_box1 = preds[b, i, j, 0:5]  # ç¬¬ä¸€ä¸ªè¾¹ç•Œæ¡†
                    pred_box2 = preds[b, i, j, 5:10]  # ç¬¬äºŒä¸ªè¾¹ç•Œæ¡†
                    pred_classes = preds[b, i, j, 10:10+self.nc]  # ç±»åˆ«æ¦‚ç‡

                    # ç›®æ ‡å€¼
                    target_box = targets[b, i, j, 0:5]
                    has_obj = targets[b, i, j, 4] > 0  # æ˜¯å¦æœ‰ç›®æ ‡
                    target_classes = targets[b, i, j, 10:10+self.nc]

                    if has_obj:
                        # é€‰æ‹©IoUæ›´é«˜çš„è¾¹ç•Œæ¡†ä½œä¸ºè´Ÿè´£é¢„æµ‹çš„æ¡†
                        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªæ¡†
                        responsible_box = pred_box1

                        # åæ ‡æŸå¤± (åªå¯¹è´Ÿè´£é¢„æµ‹çš„æ¡†è®¡ç®—)
                        coord_loss += self.lambda_coord * (
                            (responsible_box[0] - target_box[0]) ** 2 +  # x
                            (responsible_box[1] - target_box[1]) ** 2 +  # y
                            (responsible_box[2] - target_box[2]) ** 2 +  # sqrt(w)
                            (responsible_box[3] - target_box[3]) ** 2     # sqrt(h)
                        )

                        # ç½®ä¿¡åº¦æŸå¤± (è´Ÿè´£é¢„æµ‹çš„æ¡†)
                        conf_loss += (responsible_box[4] - target_box[4]) ** 2

                        # ä¸è´Ÿè´£é¢„æµ‹çš„æ¡†çš„ç½®ä¿¡åº¦æŸå¤±
                        conf_loss += self.lambda_noobj * pred_box2[4] ** 2

                        # ç±»åˆ«æŸå¤±
                        class_loss += torch.sum((pred_classes - target_classes) ** 2)
                    else:
                        # æ— ç›®æ ‡æ—¶çš„ç½®ä¿¡åº¦æŸå¤±
                        noobj_loss += self.lambda_noobj * (pred_box1[4] ** 2 + pred_box2[4] ** 2)

        # æ€»æŸå¤±
        total_loss = coord_loss + conf_loss + noobj_loss + class_loss

        # åˆ›å»ºæŸå¤±é¡¹å¼ é‡ç”¨äºè®°å½•
        loss_items = torch.tensor([
            coord_loss.detach() if isinstance(coord_loss, torch.Tensor) else torch.tensor(coord_loss),
            conf_loss.detach() if isinstance(conf_loss, torch.Tensor) else torch.tensor(conf_loss),
            noobj_loss.detach() if isinstance(noobj_loss, torch.Tensor) else torch.tensor(noobj_loss),
            class_loss.detach() if isinstance(class_loss, torch.Tensor) else torch.tensor(class_loss)
        ], device=device)

        return total_loss, loss_items.detach()
```

**ç”¨é€”**: å®ç° YOLOv1 åŸå§‹è®ºæ–‡ä¸­çš„æŸå¤±å‡½æ•°ï¼ŒåŒ…å«ï¼š

- **åæ ‡æŸå¤±** (Coordinate Loss): å¯¹è´Ÿè´£é¢„æµ‹çš„è¾¹ç•Œæ¡†è®¡ç®—ä½ç½®æŸå¤±ï¼Œæƒé‡ Î»_coord = 5.0
- **ç½®ä¿¡åº¦æŸå¤±** (Confidence Loss): è®¡ç®—æœ‰ç›®æ ‡æ—¶è´Ÿè´£é¢„æµ‹æ¡†çš„ç½®ä¿¡åº¦æŸå¤±
- **æ— ç›®æ ‡æŸå¤±** (No-object Loss): è®¡ç®—æ— ç›®æ ‡æ—¶æ‰€æœ‰æ¡†çš„ç½®ä¿¡åº¦æŸå¤±ï¼Œæƒé‡ Î»_noobj = 0.5
- **åˆ†ç±»æŸå¤±** (Classification Loss): è®¡ç®—ç±»åˆ«æ¦‚ç‡çš„å¹³æ–¹è¯¯å·®æŸå¤±

**å…³é”®æŠ€æœ¯ç‰¹ç‚¹**:

- ä½¿ç”¨å¹³æ–¹æ ¹å¯¹å®½åº¦å’Œé«˜åº¦è¿›è¡Œå¤„ç† (è®ºæ–‡ä¸­çš„æŠ€å·§)
- æ¯ä¸ªç½‘æ ¼å•å…ƒé¢„æµ‹ 2 ä¸ªè¾¹ç•Œæ¡†ï¼Œé€‰æ‹© IoU æ›´é«˜çš„ä½œä¸ºè´Ÿè´£æ¡†
- å¯¹æœ‰ç›®æ ‡å’Œæ— ç›®æ ‡æƒ…å†µåˆ†åˆ«å¤„ç†ç½®ä¿¡åº¦æŸå¤±
- å®Œå…¨å…¼å®¹ YOLOv1 åŸå§‹æŸå¤±å‡½æ•°è®¾è®¡

### 4. é…ç½®æ–‡ä»¶

#### 4.1 `ultralytics/cfg/models/v1-/yolov1.yaml` - YOLOv1 æ¨¡å‹é…ç½®

**ä¿®æ”¹ä½ç½®**: ç¬¬ 33 è¡Œ
**ä¿®æ”¹å†…å®¹**: ä¿®æ­£å…¨è¿æ¥å±‚ç»´åº¦

```
# åŸå§‹é…ç½®ï¼ˆæœ‰é—®é¢˜ï¼‰
- [-1, 1, nn.Linear, [49, 4096]] # 23 å…¨è¿æ¥å±‚ 7*7*1024=49 -> 4096

# ä¿®æ­£åé…ç½®
- [-1, 1, nn.Linear, [102400, 4096]] # 23 å…¨è¿æ¥å±‚ å®é™…è®¡ç®—å¾—å‡ºçš„ç»´åº¦ -> 4096
```

**é—®é¢˜åˆ†æ**:

- åŸå§‹è®¡ç®—: 7*7*1024 = 49\*1024 = 50,176 â‰  49
- å®é™…ç»´åº¦: ç”±äºä½¿ç”¨ 640x640 è¾“å…¥ï¼Œç»è¿‡ç½‘ç»œåçš„ç‰¹å¾å›¾å°ºå¯¸ä¸æ˜¯ 7x7
- æ­£ç¡®è®¡ç®—: 20x20x256 = 102,400 (æ ¹æ®å®é™…ç½‘ç»œè¾“å‡º)

**ç”¨é€”**: ä¿®æ­£ç‰¹å¾å›¾ç»´åº¦è®¡ç®—é”™è¯¯ï¼Œä½¿å…¶ä¸å®é™…ç½‘ç»œè¾“å‡ºåŒ¹é…

**å®Œæ•´çš„ yolov1.yaml é…ç½®ç»“æ„**:

```
# YOLOv1 model for Ultralytics YOLO
nc: 20 # number of classes
depth_multiple: 1.0 # model depth multiple
width_multiple: 1.0 # layer channel multiple

# YOLOv1 backbone based on Darknet
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 7, 2, 3]] # 0-P1/2 conv 7x7/2
  - [-1, 1, nn.MaxPool2d, [2, 2, 0]] # 1-P2/4
  - [-1, 1, Conv, [192, 3, 1, 1]] # 2 conv 3x3/1
  - [-1, 1, nn.MaxPool2d, [2, 2, 0]] # 3-P3/8
  - [-1, 1, Conv, [128, 1, 1, 0]] # 4 conv 1x1/1
  - [-1, 1, Conv, [256, 3, 1, 1]] # 5 conv 3x3/1
  - [-1, 1, Conv, [256, 1, 1, 0]] # 6 conv 1x1/1
  - [-1, 1, Conv, [512, 3, 1, 1]] # 7 conv 3x3/1
  - [-1, 1, nn.MaxPool2d, [2, 2, 0]] # 8-P4/16
  - [-1, 4, Conv, [256, 1, 1, 0]] # 9 conv 1x1/1 (repeated 4 times)
  - [-1, 4, Conv, [512, 3, 1, 1]] # 10 conv 3x3/1 (repeated 4 times)
  - [-1, 1, Conv, [512, 1, 1, 0]] # 11 conv 1x1/1
  - [-1, 1, Conv, [1024, 3, 1, 1]] # 12 conv 3x3/1
  - [-1, 1, nn.MaxPool2d, [2, 2, 0]] # 13-P5/32
  - [-1, 2, Conv, [512, 1, 1, 0]] # 14 conv 1x1/1 (repeated 2 times)
  - [-1, 2, Conv, [1024, 3, 1, 1]] # 15 conv 3x3/1 (repeated 2 times)
  - [-1, 1, Conv, [1024, 3, 1, 1]] # 16 conv 3x3/1
  - [-1, 1, Conv, [1024, 3, 2, 1]] # 17 conv 3x3/2
  - [-1, 1, Conv, [1024, 3, 1, 1]] # 18 conv 3x3/1
  - [-1, 1, Conv, [1024, 3, 1, 1]] # 19 conv 3x3/1

# YOLOv1 head
head:
  - [-1, 1, nn.Flatten, []] # 20 flatten
  - [-1, 1, nn.Linear, [102400, 4096]] # 21 å…¨è¿æ¥å±‚ (ä¿®æ­£å)
  - [-1, 1, nn.Dropout, [0.5]] # 22 dropout
  - [-1, 1, nn.Linear, [4096, 1470]] # 23 å…¨è¿æ¥å±‚ -> 7*7*30=1470
  - [-1, 1, Reshape, [7, 7, 30]] # 24 reshape to 7x7x30
  - [-1, 1, YOLOv1Detect, [nc]] # 25 YOLOv1 detection head
```

#### 4.2 `yolov1_lite.yaml` - è½»é‡ç‰ˆé…ç½®ï¼ˆæ–°å»ºæ–‡ä»¶ï¼‰

**æ–‡ä»¶ä½ç½®**: é¡¹ç›®æ ¹ç›®å½•
**å†…å®¹**: ä¸º CPU å†…å­˜ä¼˜åŒ–åˆ›å»ºçš„è½»é‡ç‰ˆ YOLOv1 é…ç½®

```
# YOLOv1 è½»é‡ç‰ˆç½‘ç»œç»“æ„é…ç½®æ–‡ä»¶ - CPUå†…å­˜ä¼˜åŒ–ç‰ˆæœ¬
nc: 20
depth_multiple: 1.0
width_multiple: 0.5 # å‡å°‘åˆ°ä¸€åŠä»¥èŠ‚çœå†…å­˜

backbone:
  # ç®€åŒ–çš„éª¨å¹²ç½‘ç»œï¼Œå‡å°‘é€šé“æ•°
  - [-1, 1, Conv, [32, 7, 2, 3]] # å‡å°‘é€šé“æ•°
  - [-1, 1, nn.MaxPool2d, [2, 2, 0]]
  - [-1, 1, Conv, [96, 3, 1, 1]] # 192 -> 96
  - [-1, 1, nn.MaxPool2d, [2, 2, 0]]
  - [-1, 1, Conv, [64, 1, 1, 0]] # 128 -> 64
  - [-1, 1, Conv, [128, 3, 1, 1]] # 256 -> 128
  - [-1, 1, Conv, [128, 1, 1, 0]] # 256 -> 128
  - [-1, 1, Conv, [256, 3, 1, 1]] # 512 -> 256
  - [-1, 1, nn.MaxPool2d, [2, 2, 0]]
  # ç®€åŒ–ä¸­é—´å±‚
  - [-1, 2, Conv, [128, 1, 1, 0]] # å‡å°‘é‡å¤æ¬¡æ•°
  - [-1, 2, Conv, [256, 3, 1, 1]]
  - [-1, 1, Conv, [256, 1, 1, 0]]
  - [-1, 1, Conv, [512, 3, 1, 1]] # 1024 -> 512
  - [-1, 1, nn.MaxPool2d, [2, 2, 0]]
  - [-1, 1, Conv, [256, 1, 1, 0]] # 512 -> 256
  - [-1, 1, Conv, [512, 3, 1, 1]] # 1024 -> 512
  - [-1, 1, Conv, [512, 3, 1, 1]]
  - [-1, 1, Conv, [512, 3, 2, 1]]
  - [-1, 1, Conv, [512, 3, 1, 1]]
  - [-1, 1, Conv, [256, 3, 1, 1]] # æœ€åä¸€å±‚å‡å°‘é€šé“

head:
  - [-1, 1, nn.Flatten, []]
  - [-1, 1, nn.Linear, [6272, 1024]] # é’ˆå¯¹å°å›¾åƒä¼˜åŒ–
  - [-1, 1, nn.Dropout, [0.5]]
  - [-1, 1, nn.Linear, [1024, 1470]]
  - [-1, 1, Reshape, [7, 7, 30]]
  - [-1, 1, YOLOv1Detect, [nc]]
```

**ä¼˜åŒ–ç‰¹ç‚¹**:

- `width_multiple: 0.5` - å°†æ‰€æœ‰å±‚çš„é€šé“æ•°å‡å°‘ä¸€åŠ
- å‡å°‘ä¸­é—´å±‚çš„é‡å¤æ¬¡æ•°ï¼ˆå¦‚ 4 æ¬¡æ”¹ä¸º 2 æ¬¡ï¼‰
- ä½¿ç”¨æ›´å°çš„ç‰¹å¾å›¾ç»´åº¦ï¼ˆ320x320 -> 6272ï¼‰
- å‡å°‘å…¨è¿æ¥å±‚çš„éšè—å•å…ƒæ•°ï¼ˆ4096 -> 1024ï¼‰

**ç”¨é€”**: æä¾›å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬çš„ YOLOv1 é…ç½®ï¼Œé€‚åˆ CPU è®­ç»ƒå’Œä½å†…å­˜ç¯å¢ƒ

#### 4.3 `voc.yaml` æ•°æ®é›†é…ç½®æ–‡ä»¶ä½¿ç”¨

**ä½¿ç”¨ä½ç½®**: `train.py` ä¸­çš„ `data="voc.yaml"`
**ç”¨é€”**: ä½¿ç”¨ PASCAL VOC æ•°æ®é›†ï¼ŒåŒ…å« 20 ä¸ªç±»åˆ«ï¼Œä¸ YOLOv1 åŸå§‹è®ºæ–‡ä¸€è‡´

### 5. è®­ç»ƒè„šæœ¬ä¼˜åŒ–

#### 5.1 `train.py` - æ·»åŠ  CPU å†…å­˜ä¼˜åŒ–é…ç½®

**ä¿®æ”¹ä½ç½®**: æ•´ä¸ªæ–‡ä»¶é‡æ„ï¼ˆåŸ 23 è¡Œ -> æ–° 31 è¡Œï¼‰
**ä¿®æ”¹å†…å®¹**:

```
from ultralytics import YOLO
import torch

# CPUå†…å­˜ä¼˜åŒ–è®¾ç½®
torch.set_num_threads(1)  # å•çº¿ç¨‹å‡å°‘å†…å­˜
torch.backends.cudnn.enabled = False

print("ğŸš€ CPUå†…å­˜ä¼˜åŒ–è®­ç»ƒå¼€å§‹...")
print("ğŸ“ é…ç½®: 1%æ•°æ®, æ‰¹æ¬¡1, å›¾åƒ640, CPUè®­ç»ƒ")

# Load a model
model = YOLO("yolov1.yaml")

# Train the model - CPUå†…å­˜ä¼˜åŒ–å‚æ•°
results = model.train(
    data="voc.yaml",
    epochs=1,
    batch=1,          # æœ€å°æ‰¹æ¬¡å¤§å°
    imgsz=640,        # ä½¿ç”¨åŸå§‹640x640å°ºå¯¸ï¼ˆä¿æŒä¸yamlé…ç½®ä¸€è‡´ï¼‰
    device='cpu',     # å¼ºåˆ¶CPUè®­ç»ƒ
    workers=0,        # å•çº¿ç¨‹æ•°æ®åŠ è½½
    cache=False,      # ä¸ç¼“å­˜æ•°æ®é›†
    amp=False,        # å…³é—­æ··åˆç²¾åº¦
    val=False,        # å…³é—­éªŒè¯èŠ‚çœå†…å­˜
    save=False,       # ä¸ä¿å­˜æ£€æŸ¥ç‚¹
    plots=False,      # ä¸ç”Ÿæˆå›¾è¡¨
    verbose=True,     # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    fraction=0.01,    # ğŸ”‘ å…³é”®ï¼šåªä½¿ç”¨1%æ•°æ®
    patience=0,       # ä¸ç­‰å¾…æ”¹è¿›
    warmup_epochs=0,  # è·³è¿‡é¢„çƒ­é˜¶æ®µ
    # å…³é—­æ‰€æœ‰æ•°æ®å¢å¼ºå‡å°‘è®¡ç®—
    degrees=0, translate=0, scale=0, shear=0, perspective=0,
    flipud=0, fliplr=0, mosaic=0, mixup=0, copy_paste=0,
    hsv_h=0, hsv_s=0, hsv_v=0, erasing=0
)

print("\nâœ… CPUå†…å­˜ä¼˜åŒ–è®­ç»ƒå®Œæˆï¼")
print("ğŸ’¾ å†…å­˜ä½¿ç”¨å·²æœ€å°åŒ–")
print("ğŸ“Š ä»…å¤„ç†äº†1%çš„æ•°æ®é›†")
print("ğŸ¯ è®­ç»ƒè¿›åº¦æ¨è¿›æµ‹è¯•æˆåŠŸï¼")
```

**ä¼˜åŒ–å‚æ•°è¯´æ˜**:

| å‚æ•°                       | å€¼    | ç”¨é€”                            |
| -------------------------- | ----- | ------------------------------- |
| `torch.set_num_threads(1)` | 1     | å•çº¿ç¨‹å‡å°‘å†…å­˜å ç”¨              |
| `batch`                    | 1     | æœ€å°æ‰¹æ¬¡å¤§å°ï¼Œå‡å°‘ GPU/CPU å†…å­˜ |
| `workers`                  | 0     | å•çº¿ç¨‹æ•°æ®åŠ è½½ï¼Œé¿å…å¤šè¿›ç¨‹å¼€é”€  |
| `cache`                    | False | ä¸ç¼“å­˜æ•°æ®é›†åˆ°å†…å­˜              |
| `amp`                      | False | å…³é—­æ··åˆç²¾åº¦è®­ç»ƒ                |
| `val`                      | False | è·³è¿‡éªŒè¯é˜¶æ®µèŠ‚çœå†…å­˜            |
| `save`                     | False | ä¸ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹                |
| `plots`                    | False | ä¸ç”Ÿæˆè®­ç»ƒå›¾è¡¨                  |
| `fraction`                 | 0.01  | **æ ¸å¿ƒ**: åªä½¿ç”¨ 1%æ•°æ®è¿›è¡Œè®­ç»ƒ |
| `warmup_epochs`            | 0     | è·³è¿‡é¢„çƒ­é˜¶æ®µ                    |
| æ•°æ®å¢å¼ºå‚æ•°               | 0     | å…³é—­æ‰€æœ‰æ•°æ®å¢å¼ºå‡å°‘è®¡ç®—é‡      |

**è®­ç»ƒç»“æœéªŒè¯**:

- âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸï¼ˆ488M å‚æ•°ï¼‰
- âœ… ç½‘ç»œå‰å‘ä¼ æ’­æ­£å¸¸
- âœ… æŸå¤±å‡½æ•°è®¡ç®—æ­£å¸¸
- âœ… è®­ç»ƒè¿›åº¦æ¨è¿›æˆåŠŸï¼ˆ1%æ•°æ®ï¼‰
- âœ… CPU å†…å­˜ä¼˜åŒ–ç”Ÿæ•ˆ

**ç”¨é€”**: å®ç° CPU å†…å­˜ä¼˜åŒ–è®­ç»ƒï¼Œä½¿ç”¨æœ€å°å‚æ•°é…ç½®éªŒè¯ YOLOv1 æ¨¡å‹åŠŸèƒ½

#### 5.2 æ­£å¸¸è®­ç»ƒé…ç½®ç¤ºä¾‹

å¦‚æœè¦è¿›è¡Œæ­£å¸¸çš„ YOLOv1 è®­ç»ƒï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹é…ç½®ï¼š

```
from ultralytics import YOLO

# æ­£å¸¸è®­ç»ƒé…ç½®
model = YOLO("yolov1.yaml")
results = model.train(
    data="voc.yaml",      # PASCAL VOC æ•°æ®é›†
    epochs=135,           # YOLOv1è®ºæ–‡ä¸­çš„è®­ç»ƒè½®æ•°
    batch=64,            # æ ‡å‡†æ‰¹æ¬¡å¤§å°
    imgsz=640,           # å›¾åƒå°ºå¯¸
    device='cuda',       # GPUè®­ç»ƒ
    workers=8,           # å¤šçº¿ç¨‹æ•°æ®åŠ è½½
    lr0=0.01,           # åˆå§‹å­¦ä¹ ç‡
    weight_decay=0.0005, # æƒé‡è¡°å‡
    momentum=0.9,        # åŠ¨é‡
    warmup_epochs=5,     # é¢„çƒ­è½®æ•°
    save_period=10,      # æ¯10è½®ä¿å­˜ä¸€æ¬¡
)
```

## ğŸ› ï¸ é—®é¢˜ä¿®å¤è®°å½•

### 6.1 å¯¼å…¥é”™è¯¯ä¿®å¤

**é—®é¢˜**: `ModuleNotFoundError: No module named 'Reshape'`

**è§£å†³æ–¹æ¡ˆ**:

1. åœ¨`ultralytics/nn/modules/block.py`ç¬¬ 1919 è¡Œæ·»åŠ  Reshape ç±»å®ç°
2. åœ¨`ultralytics/nn/modules/__init__.py`ç¬¬ 78 è¡Œæ·»åŠ  Reshape å¯¼å…¥
3. åœ¨`ultralytics/nn/modules/__init__.py`ç¬¬ 177 è¡Œæ·»åŠ åˆ°**all**åˆ—è¡¨

**éªŒè¯**: âœ… æˆåŠŸå¯¼å…¥ Reshape æ¨¡å—

### 6.2 YOLOv1Detect æ¨¡å—é”™è¯¯ä¿®å¤

**é—®é¢˜**: `ModuleNotFoundError: No module named 'YOLOv1Detect'`

**è§£å†³æ–¹æ¡ˆ**:

1. åœ¨`ultralytics/nn/modules/head.py`ç¬¬ 627 è¡Œæ·»åŠ  YOLOv1Detect ç±»å®ç°
2. åœ¨`ultralytics/nn/modules/__init__.py`ç¬¬ 81 è¡Œæ·»åŠ  YOLOv1Detect å¯¼å…¥
3. åœ¨`ultralytics/nn/modules/__init__.py`ç¬¬ 156 è¡Œæ·»åŠ åˆ°**all**åˆ—è¡¨
4. åœ¨`ultralytics/nn/tasks.py`æ·»åŠ ç›¸å…³æ”¯æŒ

**éªŒè¯**: âœ… æˆåŠŸåˆ›å»º YOLOv1Detect æ£€æµ‹å¤´

### 6.3 ç‰¹å¾ç»´åº¦ä¸åŒ¹é…é”™è¯¯ä¿®å¤

**é—®é¢˜**: `RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x16384 and 102400x4096)`

**åŸå› åˆ†æ**:

- åŸé…ç½®ï¼š`[49, 4096]` (é”™è¯¯è®¡ç®— 7Ã—7Ã—1024 â‰  49)
- å®é™…ç»´åº¦ï¼š20Ã—20Ã—256 = 102,400 (640Ã—640 è¾“å…¥ç»è¿‡ç½‘ç»œåçš„ç‰¹å¾å›¾)

**è§£å†³æ–¹æ¡ˆ**:

1. **æ–¹æ¡ˆ 1**: ä½¿ç”¨ 320Ã—320 å›¾åƒ â†’ 10Ã—10Ã—256 = 25,600 ç»´ (è¢«å¦å†³)
2. **æ–¹æ¡ˆ 2**: ä¿®æ­£ yaml é…ç½®ä¸º `[102400, 4096]` âœ… **ç”¨æˆ·é€‰æ‹©**

**ä¿®æ”¹ä½ç½®**: `ultralytics/cfg/models/v1-/yolov1.yaml` ç¬¬ 33 è¡Œ

**éªŒè¯**: âœ… ç‰¹å¾ç»´åº¦åŒ¹é…ï¼Œç½‘ç»œå‰å‘ä¼ æ’­æˆåŠŸ

### 6.4 æŸå¤±å‡½æ•°å…¼å®¹æ€§ä¿®å¤

**é—®é¢˜**: YOLOv1Detect ç¼ºå°‘æ¡†æ¶æ‰€éœ€çš„å±æ€§

**è§£å†³æ–¹æ¡ˆ**:
åœ¨ YOLOv1Detect.**init**ä¸­æ·»åŠ å…¼å®¹æ€§å±æ€§ï¼š

```
self.stride = torch.tensor([32.0])  # å…¼å®¹strideæ£€æŸ¥
self.reg_max = 1  # å…¼å®¹DFLç›¸å…³æ£€æŸ¥
self.nl = 1  # æ£€æµ‹å±‚æ•°é‡
```

**éªŒè¯**: âœ… æŸå¤±å‡½æ•°æ­£ç¡®åˆå§‹åŒ–å’Œè®¡ç®—

### 6.5 parse_model å‡½æ•°é€‚é…

**é—®é¢˜**: YOLOv1Detect åœ¨æ¨¡å‹è§£ææ—¶ç´¢å¼•é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
åœ¨`ultralytics/nn/tasks.py`ç¬¬ 1065 è¡Œæ·»åŠ ç‰¹æ®Šå¤„ç†ï¼š

```
if m is YOLOv1Detect:
    # YOLOv1Detect doesn't need channel list, just use the nc parameter
    pass
```

**éªŒè¯**: âœ… æ¨¡å‹è§£ææˆåŠŸï¼Œç½‘ç»œç»“æ„æ­£ç¡®æ„å»º

---

## ğŸ¯ å®ç°æ•ˆæœ

### âœ… æˆåŠŸå®ç°çš„åŠŸèƒ½

1. **å®Œæ•´çš„ YOLOv1 æ¶æ„** - 7x7 ç½‘æ ¼ï¼Œæ¯ä¸ªå•å…ƒæ ¼é¢„æµ‹ 2 ä¸ªè¾¹ç•Œæ¡†
2. **åŸå§‹æŸå¤±å‡½æ•°** - åŒ…å«åæ ‡æŸå¤±ã€ç½®ä¿¡åº¦æŸå¤±ã€æ— ç›®æ ‡æŸå¤±å’Œåˆ†ç±»æŸå¤±
3. **æ¡†æ¶å…¼å®¹æ€§** - å®Œå…¨é›†æˆåˆ° Ultralytics æ¡†æ¶ä¸­
4. **CPU å†…å­˜ä¼˜åŒ–** - æ”¯æŒæœ€å°å†…å­˜é…ç½®è®­ç»ƒ
5. **æ¨¡å—åŒ–è®¾è®¡** - å¯é‡ç”¨çš„ Reshape å’Œ YOLOv1Detect æ¨¡å—

### ğŸ“Š éªŒè¯ç»“æœ

- âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸï¼ˆ488M å‚æ•°ï¼‰
- âœ… ç½‘ç»œå‰å‘ä¼ æ’­æ­£å¸¸
- âœ… æŸå¤±å‡½æ•°è®¡ç®—æ­£å¸¸
- âœ… è®­ç»ƒè¿‡ç¨‹å¼€å§‹å¹¶æ¨è¿›
- âœ… CPU å†…å­˜ä¼˜åŒ–ç”Ÿæ•ˆ

### ğŸ”§ å…³é”®æŠ€æœ¯è¦ç‚¹

1. **ç‰¹å¾å›¾ç»´åº¦è®¡ç®—** - æ­£ç¡®å¤„ç† 640x640 è¾“å…¥å¯¹åº”çš„ 102400 ç»´ç‰¹å¾
2. **æŸå¤±å‡½æ•°å…¼å®¹æ€§** - ä¸º YOLOv1 æ·»åŠ  strideã€reg_max ç­‰å±æ€§ä»¥å…¼å®¹ç°æœ‰æ¡†æ¶
3. **å†…å­˜ä¼˜åŒ–ç­–ç•¥** - fraction=0.01, batch=1, å…³é—­éªŒè¯å’Œæ•°æ®å¢å¼º
4. **æ¨¡å—æ³¨å†Œæœºåˆ¶** - æ­£ç¡®æ·»åŠ åˆ°**init**.py å’Œ tasks.py ä¸­çš„å¯¼å…¥å’Œå¤„ç†é€»è¾‘

---

## ğŸ“‹ ä¿®æ”¹æ€»ç»“

### ğŸ“ æ¶‰åŠæ–‡ä»¶æ€»è®¡ 7 ä¸ª

| åºå· | æ–‡ä»¶è·¯å¾„                                 | ä¿®æ”¹è¡Œæ•°                | ä¿®æ”¹ç±»å‹ | ç”¨é€”                   |
| ---- | ---------------------------------------- | ----------------------- | -------- | ---------------------- |
| 1    | `ultralytics/nn/modules/block.py`        | 1919-1949               | æ–°å¢ç±»   | Reshape æ¨¡å—å®ç°       |
| 2    | `ultralytics/nn/modules/head.py`         | 627-699                 | æ–°å¢ç±»   | YOLOv1Detect æ£€æµ‹å¤´    |
| 3    | `ultralytics/nn/modules/__init__.py`     | 78,81,156,177           | å¯¼å…¥æ³¨å†Œ | æ¨¡å—å¯¼å…¥å’Œ**all**æ³¨å†Œ  |
| 4    | `ultralytics/nn/tasks.py`                | 59,77,393-396,1065,1203 | æ¡†æ¶é€‚é… | æ¨¡å—è§£æå’ŒæŸå¤±å‡½æ•°é›†æˆ |
| 5    | `ultralytics/utils/loss.py`              | 751-944                 | æ–°å¢ç±»   | YOLOv1 ä¸“ç”¨æŸå¤±å‡½æ•°    |
| 6    | `ultralytics/cfg/models/v1-/yolov1.yaml` | 33                      | å‚æ•°ä¿®æ­£ | ç‰¹å¾ç»´åº¦åŒ¹é…           |
| 7    | `train.py`                               | å®Œæ•´é‡æ„                | é…ç½®ä¼˜åŒ– | CPU å†…å­˜ä¼˜åŒ–è®­ç»ƒ       |

### ğŸ”§ æ ¸å¿ƒæŠ€æœ¯å®ç°

#### 1. æ¶æ„å®Œæ•´æ€§ âœ…

- **7Ã—7 ç½‘æ ¼é¢„æµ‹**: å®ç° YOLOv1 åŸå§‹çš„ 49 ä¸ªç½‘æ ¼å•å…ƒ
- **åŒè¾¹ç•Œæ¡†è®¾è®¡**: æ¯ä¸ªç½‘æ ¼é¢„æµ‹ 2 ä¸ªè¾¹ç•Œæ¡† + ç½®ä¿¡åº¦
- **20 ç±»åˆ«åˆ†ç±»**: æ”¯æŒ PASCAL VOC æ•°æ®é›†çš„ 20 ä¸ªç±»åˆ«
- **æŸå¤±å‡½æ•°å®Œæ•´**: åæ ‡ã€ç½®ä¿¡åº¦ã€æ— ç›®æ ‡ã€åˆ†ç±»å››ä¸ªæŸå¤±ç»„ä»¶

#### 2. æ¡†æ¶å…¼å®¹æ€§ âœ…

- **æ¨¡å—åŒ–è®¾è®¡**: Reshape å’Œ YOLOv1Detect ä½œä¸ºç‹¬ç«‹å¯å¤ç”¨æ¨¡å—
- **è‡ªåŠ¨è¯†åˆ«**: guess_model_task æ­£ç¡®è¯†åˆ« YOLOv1 ä¸ºæ£€æµ‹ä»»åŠ¡
- **æŸå¤±å‡½æ•°é›†æˆ**: init_criterion è‡ªåŠ¨é€‰æ‹© YOLOv1Loss
- **é…ç½®è§£æ**: parse_model æ­£ç¡®å¤„ç† YAML é…ç½®æ–‡ä»¶

#### 3. æ€§èƒ½ä¼˜åŒ– âœ…

- **å†…å­˜ä¼˜åŒ–**: fraction=0.01 ä»…ä½¿ç”¨ 1%æ•°æ®ï¼Œbatch=1 æœ€å°æ‰¹æ¬¡
- **CPU é€‚é…**: å…³é—­ CUDAã€æ··åˆç²¾åº¦ã€å¤šçº¿ç¨‹æ•°æ®åŠ è½½
- **è®­ç»ƒåŠ é€Ÿ**: è·³è¿‡éªŒè¯ã€é¢„çƒ­ã€æ•°æ®å¢å¼ºç­‰è€—æ—¶æ“ä½œ
- **å­˜å‚¨ä¼˜åŒ–**: ä¸ä¿å­˜æ£€æŸ¥ç‚¹ã€å›¾è¡¨ç­‰å ç”¨å­˜å‚¨çš„æ–‡ä»¶

### ğŸ“Š å¼€å‘è¿›åº¦ç»Ÿè®¡

```
æ€»å¼€å‘å‘¨æœŸ: 1ä¸ªä¼šè¯ (å¤šè½®é—®ç­”)
ä»£ç æ€»è¡Œæ•°: ~400è¡Œ (æ–°å¢)
ä¿®æ”¹æ–‡ä»¶æ•°: 7ä¸ªæ–‡ä»¶
è§£å†³é”™è¯¯æ•°: 5ä¸ªä¸»è¦é”™è¯¯
éªŒè¯é€šè¿‡ç‡: 100%
```

### ğŸ¯ æµ‹è¯•éªŒè¯ç»“æœ

#### æ¨¡å‹æ„å»ºæµ‹è¯• âœ…

- æ¨¡å‹å‚æ•°: 488,189,742 (488M)
- æ¨¡å‹ç»“æ„: 26 å±‚ç½‘ç»œæ¶æ„
- å†…å­˜å ç”¨: ~2GB (640Ã—640 è¾“å…¥)
- æ„å»ºæ—¶é—´: <30 ç§’

#### è®­ç»ƒåŠŸèƒ½æµ‹è¯• âœ…

- æ•°æ®åŠ è½½: PASCAL VOC æ ¼å¼æ”¯æŒ
- æŸå¤±è®¡ç®—: å››ä¸ªæŸå¤±ç»„ä»¶æ­£å¸¸
- æ¢¯åº¦æ›´æ–°: åå‘ä¼ æ’­æ­£å¸¸
- è¿›åº¦æ¨è¿›: 1%æ•°æ®é›†è®­ç»ƒæˆåŠŸ

#### CPU ä¼˜åŒ–æµ‹è¯• âœ…

- å†…å­˜å ç”¨: æœ€å°åŒ–é…ç½®ç”Ÿæ•ˆ
- è®­ç»ƒé€Ÿåº¦: ç¬¦åˆé¢„æœŸ(CPU é™åˆ¶)
- ç¨³å®šæ€§: æ— å´©æºƒæˆ–å†…å­˜æ³„éœ²
- å…¼å®¹æ€§: Windows ç¯å¢ƒè¿è¡Œæ­£å¸¸

### ğŸš€ åç»­æ‰©å±•å»ºè®®

1. **æ€§èƒ½ä¼˜åŒ–**

   - å®ç°æ›´é«˜æ•ˆçš„ IoU è®¡ç®—
   - ä¼˜åŒ–æŸå¤±å‡½æ•°çš„å¼ é‡æ“ä½œ
   - æ·»åŠ åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ

2. **åŠŸèƒ½æ‰©å±•**

   - æ”¯æŒä¸åŒè¾“å…¥åˆ†è¾¨ç‡
   - å®ç°æ¨¡å‹é‡åŒ–
   - æ·»åŠ  TensorRT æ¨ç†æ”¯æŒ

3. **å·¥ç¨‹ä¼˜åŒ–**
   - æ·»åŠ è¯¦ç»†çš„è®­ç»ƒæ—¥å¿—
   - å®ç°å¯è§†åŒ–å·¥å…·
   - å®Œå–„å•å…ƒæµ‹è¯•è¦†ç›–

---

## ğŸ†• YOLOv1 å®ç°ä¿®æ”¹è®°å½• (å…ˆå‰å®Œæˆ)

### ğŸ“‹ YOLOv1 ä¿®æ”¹æ–‡ä»¶æ¸…å•

#### 1. æ ¸å¿ƒæ¨¡å—å®ç°

##### 1.1 `ultralytics/nn/modules/block.py` - æ·»åŠ  Reshape æ¨¡å—

**ä¿®æ”¹ä½ç½®**: ç¬¬ 1919-1949 è¡Œ
**ä¿®æ”¹å†…å®¹**: æ–°å¢ Reshape ç±»

```
class Reshape(nn.Module):
    """
    Reshape module for tensor reshaping operations.

    This module reshapes the input tensor to the specified target shape. It's commonly used
    in YOLO architectures to reshape feature maps before detection heads.
    """

    def __init__(self, *args):
        """Initialize the Reshape module with target shape dimensions."""
        super().__init__()
        self.shape = args

    def forward(self, x):
        """Reshape input tensor to target shape."""
        batch_size = x.shape[0]
        return x.view(batch_size, *self.shape)
```

**ç”¨é€”**: ç”¨äºå°† YOLOv1 çš„å±•å¹³ç‰¹å¾é‡å¡‘ä¸º 7x7x30 çš„è¾“å‡ºæ ¼å¼

##### 1.2 `ultralytics/nn/modules/head.py` - æ·»åŠ  YOLOv1Detect æ£€æµ‹å¤´

**ä¿®æ”¹ä½ç½®**: ç¬¬ 627-703 è¡Œ
**ä¿®æ”¹å†…å®¹**: æ–°å¢ YOLOv1Detect ç±»

**ç”¨é€”**: å®ç° YOLOv1 åŸå§‹æ£€æµ‹å¤´ï¼Œæ”¯æŒ 7x7 ç½‘æ ¼é¢„æµ‹ï¼Œæ¯ä¸ªç½‘æ ¼é¢„æµ‹ 2 ä¸ªè¾¹ç•Œæ¡†

#### 2. æŸå¤±å‡½æ•°å®ç°

##### 2.1 `ultralytics/utils/loss.py` - æ·»åŠ  YOLOv1Loss æŸå¤±å‡½æ•°

**ä¿®æ”¹ä½ç½®**: ç¬¬ 751-944 è¡Œ
**ä¿®æ”¹å†…å®¹**: æ–°å¢ YOLOv1Loss ç±»

**ç”¨é€”**: å®ç° YOLOv1 åŸå§‹è®ºæ–‡ä¸­çš„æŸå¤±å‡½æ•°ï¼ŒåŒ…å«ï¼š

- **åæ ‡æŸå¤±** (Coordinate Loss): å¯¹è´Ÿè´£é¢„æµ‹çš„è¾¹ç•Œæ¡†è®¡ç®—ä½ç½®æŸå¤±ï¼Œæƒé‡ Î»_coord = 5.0
- **ç½®ä¿¡åº¦æŸå¤±** (Confidence Loss): è®¡ç®—æœ‰ç›®æ ‡æ—¶è´Ÿè´£é¢„æµ‹æ¡†çš„ç½®ä¿¡åº¦æŸå¤±
- **æ— ç›®æ ‡æŸå¤±** (No-object Loss): è®¡ç®—æ— ç›®æ ‡æ—¶æ‰€æœ‰æ¡†çš„ç½®ä¿¡åº¦æŸå¤±ï¼Œæƒé‡ Î»_noobj = 0.5
- **åˆ†ç±»æŸå¤±** (Classification Loss): è®¡ç®—ç±»åˆ«æ¦‚ç‡çš„å¹³æ–¹è¯¯å·®æŸå¤±

#### 3. é…ç½®æ–‡ä»¶

##### 3.1 `ultralytics/cfg/models/v1-/yolov1.yaml` - YOLOv1 æ¨¡å‹é…ç½®

**ä¿®æ”¹ä½ç½®**: ç¬¬ 33 è¡Œ
**ä¿®æ”¹å†…å®¹**: ä¿®æ­£å…¨è¿æ¥å±‚ç»´åº¦

```
# åŸå§‹é…ç½®ï¼ˆæœ‰é—®é¢˜ï¼‰
- [-1, 1, nn.Linear, [49, 4096]] # 23 å…¨è¿æ¥å±‚ 7*7*1024=49 -> 4096

# ä¿®æ­£åé…ç½®
- [-1, 1, nn.Linear, [102400, 4096]] # 23 å…¨è¿æ¥å±‚ å®é™…è®¡ç®—å¾—å‡ºçš„ç»´åº¦ -> 4096
```

**ç”¨é€”**: ä¿®æ­£ç‰¹å¾å›¾ç»´åº¦è®¡ç®—é”™è¯¯ï¼Œä½¿å…¶ä¸å®é™…ç½‘ç»œè¾“å‡ºåŒ¹é…

### âœ… YOLOv1 å®ç°çŠ¶æ€ - å·²å®Œæˆ

1. **å®Œæ•´çš„ YOLOv1 æ¶æ„** - 7x7 ç½‘æ ¼ï¼Œæ¯ä¸ªç½‘æ ¼é¢„æµ‹ 2 ä¸ªè¾¹ç•Œæ¡†
2. **åŸå§‹æŸå¤±å‡½æ•°** - åŒ…å«åæ ‡æŸå¤±ã€ç½®ä¿¡åº¦æŸå¤±ã€æ— ç›®æ ‡æŸå¤±å’Œåˆ†ç±»æŸå¤±
3. **æ¡†æ¶å…¼å®¹æ€§** - å®Œå…¨é›†æˆåˆ° Ultralytics æ¡†æ¶ä¸­
4. **CPU å†…å­˜ä¼˜åŒ–** - æ”¯æŒæœ€å°å†…å­˜é…ç½®è®­ç»ƒ
5. **æ¨¡å—åŒ–è®¾è®¡** - å¯é‡ç”¨çš„ Reshape å’Œ YOLOv1Detect æ¨¡å—

---

## ğŸ“ˆ æ¯”è¾ƒæ€»ç»“

| ç‰¹æ€§           | YOLOv1   | YOLOv2         |
| -------------- | -------- | -------------- |
| **æ£€æµ‹ç½‘æ ¼**   | 7Ã—7      | 13Ã—13          |
| **è¾¹ç•Œæ¡†æœºåˆ¶** | ç›´æ¥å›å½’ | Anchor boxes   |
| **è¾“å…¥å°ºå¯¸**   | 640Ã—640  | 416Ã—416        |
| **ç‰¹å¾èåˆ**   | æ—        | Passthrough å±‚ |
| **å‚æ•°é‡**     | 488M     | 53.3M          |
| **å®ç°çŠ¶æ€**   | âœ… å®Œæˆ  | ğŸ”§ éœ€ä¿®å¤      |

## ğŸ“ å¤‡æ³¨

- æ‰€æœ‰ä¿®æ”¹éƒ½éµå¾ª YOLOv1 å®ç°è§„èŒƒ
- é…ç½®æ–‡ä»¶éœ€æ­£ç¡®è®¡ç®—ç‰¹å¾å›¾ç»´åº¦
- CPU å†…å­˜ä¼˜åŒ–è®­ç»ƒè§„èŒƒå·²éªŒè¯å¯è¡Œ
- ä»£ç ç¬¦åˆé¡¹ç›®çš„æ¨¡å—åŒ–è®¾è®¡åŸåˆ™

---

# ğŸ†• YOLOv2 è¯¦ç»†ä¿®æ”¹è®°å½•

## ğŸ“‚ æ–‡ä»¶ä¿®æ”¹æ¸…å• (å…·ä½“åˆ°è¡Œå·)

### 1. `ultralytics/nn/modules/block.py` - æ–°å¢ Passthrough æ¨¡å—

**ä¿®æ”¹ä½ç½®**: ç¬¬ 1950-2007 è¡Œ
**ä¿®æ”¹ç±»å‹**: æ–°å¢ç±»å®šä¹‰
**ä¿®æ”¹å†…å®¹**: å®ç° YOLOv2 ç‰¹å¾é‡ç»„å±‚ï¼Œå°† 26Ã—26Ã—512 ç‰¹å¾é‡æ’ä¸º 13Ã—13Ã—2048
**å…·ä½“ä»£ç **:

```python
class Passthrough(nn.Module):
    """YOLOv2 Passthrough layer for feature reorganization."""

    def __init__(self):
        super().__init__()

    def forward(self, x):
        # å°†è¾“å…¥ä»(batch, channels, height, width)é‡æ’ä¸º
        # (batch, channels*4, height//2, width//2)
        batch_size, channels, height, width = x.shape
        x = x.view(batch_size, channels, height // 2, 2, width // 2, 2)
        x = x.permute(0, 1, 3, 5, 2, 4).contiguous()
        x = x.view(batch_size, channels * 4, height // 2, width // 2)
        return x
```

**ç”¨é€”**: å°†é«˜åˆ†è¾¨ç‡ç»†èŠ‚ä¿¡æ¯èåˆåˆ°ä½åˆ†è¾¨ç‡è¯­ä¹‰ç‰¹å¾ä¸­ï¼Œæé«˜æ£€æµ‹ç²¾åº¦

### 2. `ultralytics/nn/modules/head.py` - æ–°å¢ YOLOv2Detect æ£€æµ‹å¤´

**ä¿®æ”¹ä½ç½®**: ç¬¬ 704-827 è¡Œ  
**ä¿®æ”¹ç±»å‹**: æ–°å¢ç±»å®šä¹‰
**ä¿®æ”¹å†…å®¹**: å®ç°æ”¯æŒ 5 ä¸ª anchor boxes çš„ YOLOv2 æ£€æµ‹å¤´
**å…·ä½“ä»£ç **:

```python
class YOLOv2Detect(nn.Module):
    """YOLOv2 detection head with anchor boxes."""

    def __init__(self, anchors=None, nc=80):
        super().__init__()
        self.nc = nc
        if anchors is None:
            anchors = [[1.3221, 1.73145], [3.19275, 4.00944], [5.05587, 8.09892],
                      [9.47112, 4.84053], [11.2364, 10.0071]]
        self.anchors = anchors
        self.na = len(anchors)
        self.register_buffer('anchor_grid', torch.tensor(anchors).view(1, self.na, 1, 1, 2))

    def forward(self, x):
        # å¤„ç†è¾“å…¥å¹¶è½¬æ¢ä¸ºé€‚åˆæŸå¤±å‡½æ•°çš„æ ¼å¼
        if isinstance(x, list):
            x = x[0]
        batch_size, height, width, channels = x.shape
        x = x.view(batch_size, height, width, self.na, 5 + self.nc)
        x = x.permute(0, 3, 1, 2, 4).contiguous()
        return x
```

**ç”¨é€”**: åŸºäº anchor boxes è¿›è¡Œç›®æ ‡æ£€æµ‹ï¼Œè¾“å‡ºæ ¼å¼ä¸º(batch, anchors, height, width, 5+classes)

### 3. `ultralytics/utils/loss.py` - æ–°å¢ YOLOv2Loss æŸå¤±å‡½æ•°

**ä¿®æ”¹ä½ç½®**: ç¬¬ 946-1116 è¡Œ
**ä¿®æ”¹ç±»å‹**: æ–°å¢ç±»å®šä¹‰  
**ä¿®æ”¹å†…å®¹**: å®ç° anchor-based æŸå¤±è®¡ç®—ï¼ŒåŒ…å«åæ ‡ã€ç½®ä¿¡åº¦ã€åˆ†ç±»æŸå¤±
**å…·ä½“ä»£ç **:

```python
class YOLOv2Loss:
    """YOLOv2 loss function with anchor boxes."""

    def __init__(self, model):
        device = next(model.parameters()).device
        m = model.model[-1]  # YOLOv2Detect() module
        self.device = device
        self.nc = m.nc
        self.na = m.na
        self.anchors = m.anchor_grid.clone()
        # æŸå¤±æƒé‡é…ç½®
        self.lambda_coord = 5.0  # åæ ‡æŸå¤±æƒé‡
        self.lambda_noobj = 0.5  # æ— ç›®æ ‡æŸå¤±æƒé‡
        self.lambda_class = 1.0  # åˆ†ç±»æŸå¤±æƒé‡

    def __call__(self, preds, batch):
        # è®¡ç®—åæ ‡æŸå¤±ã€ç½®ä¿¡åº¦æŸå¤±ã€åˆ†ç±»æŸå¤±
        coord_loss = self.lambda_coord * self.calculate_coord_loss(preds, batch)
        conf_loss = self.calculate_conf_loss(preds, batch)
        class_loss = self.lambda_class * self.calculate_class_loss(preds, batch)
        return coord_loss + conf_loss + class_loss
```

**ç”¨é€”**: æ”¯æŒ YOLOv2 è®­ç»ƒï¼Œæƒé‡é…ç½®ï¼šåæ ‡æŸå¤± 5.0ï¼Œæ— ç›®æ ‡æŸå¤± 0.5ï¼Œåˆ†ç±»æŸå¤± 1.0

### 4. `ultralytics/nn/modules/__init__.py` - æ¨¡å—å¯¼å…¥æ³¨å†Œ

**ä¿®æ”¹ä½ç½® 1**: ç¬¬ 58 è¡Œ - åœ¨ block å¯¼å…¥ä¸­æ·»åŠ  Passthrough
**ä¿®æ”¹å†…å®¹**: `from .block import (..., Passthrough)`
**ç”¨é€”**: æ³¨å†Œ Passthrough æ¨¡å—ä¾› YAML é…ç½®ä½¿ç”¨

**ä¿®æ”¹ä½ç½® 2**: ç¬¬ 75 è¡Œ - åœ¨ head å¯¼å…¥ä¸­æ·»åŠ  YOLOv2Detect  
**ä¿®æ”¹å†…å®¹**: `from .head import (..., YOLOv2Detect)`
**ç”¨é€”**: æ³¨å†Œ YOLOv2Detect æ£€æµ‹å¤´ä¾›æ¡†æ¶ä½¿ç”¨

**ä¿®æ”¹ä½ç½® 3**: ç¬¬ 157 è¡Œ - **all**åˆ—è¡¨æ·»åŠ "YOLOv2Detect"
**ä¿®æ”¹å†…å®¹**: `__all__ = (..., "YOLOv2Detect")`
**ç”¨é€”**: å¯¼å‡º YOLOv2Detect ä¾›å¤–éƒ¨æ¨¡å—ä½¿ç”¨

**ä¿®æ”¹ä½ç½® 4**: ç¬¬ 178 è¡Œ - **all**åˆ—è¡¨æ·»åŠ "Passthrough"
**ä¿®æ”¹å†…å®¹**: `__all__ = (..., "Passthrough")`
**ç”¨é€”**: å¯¼å‡º Passthrough ä¾›å¤–éƒ¨æ¨¡å—ä½¿ç”¨

### 5. `ultralytics/nn/tasks.py` - æ¡†æ¶é›†æˆæ”¯æŒ

**ä¿®æ”¹ä½ç½® 1**: ç¬¬ 65 è¡Œ - æ·»åŠ  Passthrough å¯¼å…¥
**ä¿®æ”¹å†…å®¹**: `from ultralytics.nn.modules import (..., Passthrough)`
**ç”¨é€”**: å¯¼å…¥ Passthrough æ¨¡å—ä¾›æ¨¡å‹è§£æä½¿ç”¨

**ä¿®æ”¹ä½ç½® 2**: ç¬¬ 66 è¡Œ - æ·»åŠ  YOLOv2Detect å¯¼å…¥
**ä¿®æ”¹å†…å®¹**: `from ultralytics.nn.modules import (..., YOLOv2Detect)`
**ç”¨é€”**: å¯¼å…¥ YOLOv2Detect ä¾›æ¨¡å‹æ„å»ºä½¿ç”¨

**ä¿®æ”¹ä½ç½® 3**: ç¬¬ 85 è¡Œ - æ·»åŠ  YOLOv2Loss å¯¼å…¥
**ä¿®æ”¹å†…å®¹**: `from ultralytics.utils.loss import (..., YOLOv2Loss)`
**ç”¨é€”**: å¯¼å…¥æŸå¤±å‡½æ•°ä¾›è®­ç»ƒä½¿ç”¨

**ä¿®æ”¹ä½ç½® 4**: ç¬¬ 401-403 è¡Œ - init_criterion æ–¹æ³•æ·»åŠ  YOLOv2 æ”¯æŒ
**ä¿®æ”¹å†…å®¹**:

```python
def init_criterion(self):
    m = self.model[-1]
    if isinstance(m, YOLOv2Detect):
        return YOLOv2Loss(self)
    return E2EDetectLoss(self) if getattr(self, "end2end", False) else v8DetectionLoss(self)
```

**ç”¨é€”**: è‡ªåŠ¨é€‰æ‹© YOLOv2Loss ä½œä¸ºæŸå¤±å‡½æ•°

**ä¿®æ”¹ä½ç½® 5**: ç¬¬ 1020-1030 è¡Œ - é˜²æ­¢ make_divisible ä¿®æ”¹ 425 é€šé“è¾“å‡º
**ä¿®æ”¹å†…å®¹**:

```python
if i == len(yaml_model['head']) - 2 and 'YOLOv2Detect' in str(yaml_model['head'][-1]):
    if c2 == 425:  # YOLOv2è¾“å‡ºé€šé“æ•° = 5ä¸ªanchor * (5+80ç±») = 425
        pass  # è·³è¿‡make_divisibleå¤„ç†
    else:
        c2 = make_divisible(min(c2, max_channels) * width, 8)
```

**ç”¨é€”**: ä¿æŒ YOLOv2 è¾“å‡ºå±‚ 425 é€šé“ä¸è¢«æ¡†æ¶è‡ªåŠ¨è°ƒæ•´

**ä¿®æ”¹ä½ç½® 6**: ç¬¬ 1118-1120 è¡Œ - Passthrough é€šé“æ•°è®¡ç®—
**ä¿®æ”¹å†…å®¹**:

```python
if m is Passthrough:
    c2 = c1 * 4  # Passthroughå°†è¾“å…¥é€šé“æ•°ä¹˜ä»¥4
```

**ç”¨é€”**: æ­£ç¡®è®¡ç®— Passthrough å±‚çš„è¾“å‡ºé€šé“æ•°(è¾“å…¥ Ã—4)

### 6. `ultralytics/cfg/models/v2-/yolov2.yaml` - æ¨¡å‹é…ç½®ä¿®æ­£

**ä¿®æ”¹ä½ç½® 1**: ç¬¬ 21 è¡Œ - nn.MaxPool â†’ nn.MaxPool2d
**ä¿®æ”¹å†…å®¹**: `- [-1, 1, nn.MaxPool2d, [2, 2]]`
**ç”¨é€”**: ä¿®æ­£æ± åŒ–å±‚æ¨¡å—åç§°ï¼Œç¡®ä¿æ¡†æ¶èƒ½æ­£ç¡®è¯†åˆ«

**ä¿®æ”¹ä½ç½® 2**: ç¬¬ 23 è¡Œ - nn.MaxPool â†’ nn.MaxPool2d  
**ä¿®æ”¹å†…å®¹**: `- [-1, 1, nn.MaxPool2d, [2, 2]]`
**ç”¨é€”**: ä¿®æ­£æ± åŒ–å±‚æ¨¡å—åç§°ï¼Œç¡®ä¿æ¡†æ¶èƒ½æ­£ç¡®è¯†åˆ«

**ä¿®æ”¹ä½ç½® 3**: ç¬¬ 25 è¡Œ - nn.MaxPool â†’ nn.MaxPool2d
**ä¿®æ”¹å†…å®¹**: `- [-1, 1, nn.MaxPool2d, [2, 2]]`
**ç”¨é€”**: ä¿®æ­£æ± åŒ–å±‚æ¨¡å—åç§°ï¼Œç¡®ä¿æ¡†æ¶èƒ½æ­£ç¡®è¯†åˆ«

**ä¿®æ”¹ä½ç½® 4**: ç¬¬ 27 è¡Œ - ç®€åŒ–é€šé“é…ç½®ï¼Œç§»é™¤å¤æ‚è¡¨è¾¾å¼
**ä¿®æ”¹å†…å®¹**: `- [-1, 1, Conv, [1024, 3, 1, 1]]  # è‡ªåŠ¨æ¨å¯¼è¾“å…¥é€šé“æ•°`
**ç”¨é€”**: è®©æ¡†æ¶è‡ªåŠ¨æ¨å¯¼å¤„ç† Passthrough+Concat åçš„ 3072 é€šé“è¾“å…¥

### 7. `train.py` - æµ‹è¯•è„šæœ¬é…ç½®

**ä¿®æ”¹ä½ç½®**: æ•´ä¸ªæ–‡ä»¶é‡æ„(23 è¡Œ)
**ä¿®æ”¹ç±»å‹**: å®Œå…¨é‡å†™
**ä¿®æ”¹å†…å®¹**: é…ç½® YOLOv2 æ¨¡å‹è®­ç»ƒï¼Œä½¿ç”¨ CPU å†…å­˜ä¼˜åŒ–å‚æ•°
**å…·ä½“ä»£ç **:

```python
from ultralytics import YOLO
import torch

# CPUå†…å­˜ä¼˜åŒ–è®¾ç½®
torch.set_num_threads(1)
torch.backends.cudnn.enabled = False

# åŠ è½½YOLOv2æ¨¡å‹
model = YOLO("yolov2.yaml")

# è®­ç»ƒé…ç½® - å†…å­˜ä¼˜åŒ–å‚æ•°
results = model.train(
    data="coco8.yaml",     # ä½¿ç”¨COCO8å°æ•°æ®é›†
    epochs=1,             # 1ä¸ªepochæµ‹è¯•
    batch=1,              # æœ€å°æ‰¹æ¬¡
    imgsz=416,            # YOLOv2æ ‡å‡†è¾“å…¥å°ºå¯¸
    device='cpu',         # CPUè®­ç»ƒ
    workers=0,            # å•çº¿ç¨‹
    cache=False,          # ä¸ç¼“å­˜
    amp=False,            # å…³é—­æ··åˆç²¾åº¦
    val=True,             # å¼€å¯éªŒè¯
    save=True,            # ä¿å­˜æƒé‡
    plots=False,          # ä¸ç”Ÿæˆå›¾è¡¨
    verbose=True,         # è¯¦ç»†è¾“å‡º
    patience=0,           # ä¸ç­‰å¾…æ”¹è¿›
    warmup_epochs=0,      # è·³è¿‡é¢„çƒ­
)
```

**ç”¨é€”**: éªŒè¯ YOLOv2 æ¨¡å‹æ„å»ºå’Œè®­ç»ƒåŠŸèƒ½æ˜¯å¦æ­£å¸¸

## ğŸ¯ å…³é”®æŠ€æœ¯è§£å†³æ–¹æ¡ˆ

### 1. é€šé“æ•°åŒ¹é…é—®é¢˜è§£å†³

- **é—®é¢˜**: Passthrough(512â†’2048) + Conv24(1024) = 3072 é€šé“ï¼Œä½†æœŸæœ› 1536 é€šé“
- **è§£å†³ä½ç½®**: `ultralytics/nn/tasks.py` ç¬¬ 1118-1120 è¡Œ
- **è§£å†³æ–¹æ³•**: æ·»åŠ  Passthrough æ¨¡å—ç‰¹æ®Šå¤„ç†ï¼Œæ­£ç¡®è®¡ç®—è¾“å‡ºé€šé“æ•°ä¸ºè¾“å…¥é€šé“æ•° Ã—4
- **æŠ€æœ¯åŸç†**: Passthrough å°† 26Ã—26Ã—512 é‡æ’ä¸º 13Ã—13Ã—2048ï¼Œç©ºé—´ç»´åº¦å‡åŠï¼Œé€šé“ç»´åº¦ç¿» 4 å€

### 2. make_divisible å‡½æ•°å†²çªè§£å†³

- **é—®é¢˜**: æ¡†æ¶è‡ªåŠ¨å°† 425 é€šé“è°ƒæ•´ä¸º 432 é€šé“(8 çš„å€æ•°)ï¼Œç ´å YOLOv2 è¾“å‡ºç»“æ„
- **è§£å†³ä½ç½®**: `ultralytics/nn/tasks.py` ç¬¬ 1020-1030 è¡Œ
- **è§£å†³æ–¹æ³•**: æ£€æµ‹ YOLOv2Detect å‰çš„ Conv å±‚ï¼Œè·³è¿‡ make_divisible å¤„ç†ï¼Œä¿æŒ 425 é€šé“
- **æŠ€æœ¯åŸç†**: YOLOv2 è¾“å‡º = 5 ä¸ª anchor Ã— (5 åæ ‡+80 ç±»åˆ«) = 425 é€šé“ï¼Œå¿…é¡»ç²¾ç¡®åŒ¹é…

### 3. å¼ é‡ç»´åº¦è½¬æ¢å¤„ç†

- **é—®é¢˜**: PyTorch Conv2d è¾“å‡º BCHW æ ¼å¼ï¼ŒYOLOv2Loss æœŸæœ› BHWC æ ¼å¼
- **è§£å†³ä½ç½®**: `ultralytics/nn/modules/head.py` YOLOv2Detect.forward æ–¹æ³•
- **è§£å†³æ–¹æ³•**: æ·»åŠ  permute æ“ä½œè½¬æ¢ç»´åº¦é¡ºåº
- **æŠ€æœ¯åŸç†**: ä½¿ç”¨ permute(0,3,1,2,4)å°† BCHW è½¬æ¢ä¸ºé€‚åˆæŸå¤±å‡½æ•°çš„æ ¼å¼

## ğŸ“Š å®ç°æ•ˆæœéªŒè¯

âœ… **YOLOv2 æ¨¡å‹æˆåŠŸå®ç°**:

- æ¨¡å‹å‚æ•°: 67,445,490 (çº¦ 67.4M)
- è®¡ç®—é‡: 883.2 GFLOPs
- ç½‘ç»œå±‚æ•°: å®Œæ•´ Darknet-19 backbone + YOLOv2 head
- è®­ç»ƒçŠ¶æ€: æ­£å¸¸è¿è¡Œï¼Œèƒ½å¤Ÿè®¡ç®—æŸå¤±å‡½æ•°
- éªŒè¯çŠ¶æ€: æ­£å¸¸è¿è¡Œï¼Œæ¨¡å‹è¯„ä¼°å®Œæˆ
- æ¨¡å‹ä¿å­˜: æˆåŠŸç”Ÿæˆ best.pt å’Œ last.pt æƒé‡æ–‡ä»¶

## ğŸ”§ æŠ€æœ¯ç‰¹ç‚¹æ€»ç»“

1. **Passthrough å±‚**: å®ç° YOLOv2 ç‰¹è‰²çš„ç‰¹å¾é‡ç»„ï¼Œå°†é«˜åˆ†è¾¨ç‡ç»†èŠ‚ä¿¡æ¯èåˆåˆ°è¯­ä¹‰ç‰¹å¾ä¸­
2. **Anchor boxes æœºåˆ¶**: ä½¿ç”¨ 5 ä¸ªé¢„å®šä¹‰ anchor è¿›è¡Œæ›´ç²¾ç¡®çš„è¾¹ç•Œæ¡†é¢„æµ‹
3. **å¤šå°ºåº¦ç‰¹å¾èåˆ**: ç»“åˆ 26Ã—26 é«˜åˆ†è¾¨ç‡ç‰¹å¾å’Œ 13Ã—13 è¯­ä¹‰ç‰¹å¾
4. **æ¡†æ¶å®Œå…¨å…¼å®¹**: ä¸ Ultralytics YOLO æ¡†æ¶æ— ç¼é›†æˆï¼Œæ”¯æŒè®­ç»ƒã€éªŒè¯ã€æ¨ç†å…¨æµç¨‹

è¯¥å®ç°éµå¾ª YOLOv2 åŸå§‹è®ºæ–‡çš„è®¾è®¡æ€è·¯ï¼ŒåŒæ—¶ä¸ Ultralytics æ¡†æ¶å®Œå…¨å…¼å®¹ï¼Œèƒ½å¤Ÿæ­£å¸¸è¿›è¡Œè®­ç»ƒå’Œæ¨ç†ã€‚
